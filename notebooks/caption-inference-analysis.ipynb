{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "499e07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, DatasetDict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ffadbb",
   "metadata": {},
   "source": [
    "## 1. Load Data from All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "422d057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zero_shot/train: 1000 samples\n",
      "Loaded zero_shot/validation: 100 samples\n",
      "Loaded zero_shot/test: 100 samples\n",
      "Loaded base_random/train: 1000 samples\n",
      "Loaded base_random/validation: 100 samples\n",
      "Loaded base_random/test: 100 samples\n",
      "Loaded base_vae/train: 1000 samples\n",
      "Loaded base_vae/validation: 100 samples\n",
      "Loaded base_vae/test: 100 samples\n",
      "Loaded ft_random/train: 1000 samples\n",
      "Loaded ft_random/validation: 100 samples\n",
      "Loaded ft_random/test: 100 samples\n",
      "Loaded ft_vae/train: 1000 samples\n",
      "Loaded ft_vae/validation: 100 samples\n",
      "Loaded ft_vae/test: 100 samples\n",
      "\n",
      "Loaded data for 5 models across 3 splits\n"
     ]
    }
   ],
   "source": [
    "# Define base directory and model names\n",
    "base_dir = Path(\"../outputs/caption_inference\")\n",
    "models = ['zero_shot', 'base_random', 'base_vae', 'ft_random', 'ft_vae']\n",
    "splits = ['train', 'validation', 'test']\n",
    "\n",
    "# Load all predictions and metrics\n",
    "predictions = {}\n",
    "metrics = {}\n",
    "\n",
    "for model in models:\n",
    "    predictions[model] = {}\n",
    "    metrics[model] = {}\n",
    "    \n",
    "    for split in splits:\n",
    "        # Load predictions\n",
    "        pred_path = base_dir / model / f\"{split}_predictions.csv\"\n",
    "        if pred_path.exists():\n",
    "            predictions[model][split] = pd.read_csv(pred_path)\n",
    "            print(f\"Loaded {model}/{split}: {len(predictions[model][split])} samples\")\n",
    "        \n",
    "        # Load quality metrics\n",
    "        metrics_path = base_dir / model / f\"{split}_quality_metrics.json\"\n",
    "        if metrics_path.exists():\n",
    "            with open(metrics_path, 'r') as f:\n",
    "                metrics[model][split] = json.load(f)\n",
    "\n",
    "print(f\"\\nLoaded data for {len(models)} models across {len(splits)} splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc60bd1f",
   "metadata": {},
   "source": [
    "## 2. Filter Empty Samples\n",
    "\n",
    "Remove samples with empty or missing captions/predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "922aaa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_predictions = {}\n",
    "filtering_stats = {}\n",
    "\n",
    "for model in models:\n",
    "    filtered_predictions[model] = {}\n",
    "    filtering_stats[model] = {}\n",
    "    \n",
    "    for split in splits:\n",
    "        if split not in predictions[model]:\n",
    "            continue\n",
    "            \n",
    "        df = predictions[model][split].copy()\n",
    "        original_count = len(df)\n",
    "        \n",
    "        pred_col = 'prediction'\n",
    "        df = df[df[pred_col].notna()]\n",
    "        df = df[df[pred_col].astype(str).str.strip() != '']\n",
    "        df = df[df[pred_col].astype(str).str.lower() != 'nan']\n",
    "        df['prediction_length'] = df[pred_col].astype(str).apply(len)\n",
    "        \n",
    "        filtered_predictions[model][split] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02de8988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged zero_shot: 500 samples\n",
      "Merged base_random: 500 samples\n",
      "Merged base_vae: 500 samples\n",
      "Merged ft_random: 500 samples\n",
      "Merged ft_vae: 500 samples\n"
     ]
    }
   ],
   "source": [
    "# Merge all splits for each model and trim to first 500 samples\n",
    "merged_predictions = {}\n",
    "for model in models:\n",
    "    merged_df = pd.DataFrame()\n",
    "    \n",
    "    for split in splits:\n",
    "        if split in filtered_predictions[model]:\n",
    "            merged_df = pd.concat([merged_df, filtered_predictions[model][split]], ignore_index=True)\n",
    "    \n",
    "    merged_predictions[model] = merged_df.head(500)\n",
    "    print(f\"Merged {model}: {len(merged_predictions[model])} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50a9a9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>aspect_list</th>\n",
       "      <th>prediction</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>llm_judge_score</th>\n",
       "      <th>llm_judge_reasoning</th>\n",
       "      <th>prediction_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_0000</td>\n",
       "      <td>punchy kick, happy, passionate, scary, eerie, ...</td>\n",
       "      <td>describe this song.\\n\\nThis up-tempo track is ...</td>\n",
       "      <td>8.472451</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The description accurately incorporates all th...</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_0001</td>\n",
       "      <td>e-bass, fun, hip hop, rhythmic patter</td>\n",
       "      <td>info.\\n\\nThis track starts off with an infecti...</td>\n",
       "      <td>7.610440</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The description is somewhat accurate but lacks...</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_0002</td>\n",
       "      <td>no percussion, punchy kick, electric guitar, v...</td>\n",
       "      <td>:\\n\\nIn this hauntingly beautiful composition,...</td>\n",
       "      <td>14.413651</td>\n",
       "      <td>8.0</td>\n",
       "      <td>The description offers a rich and detailed acc...</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_0003</td>\n",
       "      <td>acoustic drums, shimmering shakers, male voice...</td>\n",
       "      <td>only this:\\n**Song Description**\\n\\nIn \"Slow S...</td>\n",
       "      <td>12.282628</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The description is fairly accurate and coheren...</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_0004</td>\n",
       "      <td>keyboard accompaniment, shimmering cymbals, ba...</td>\n",
       "      <td>atmospheric.\\n\\nWhat an intriguing combination...</td>\n",
       "      <td>9.046556</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The description attempts to incorporate most o...</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                        aspect_list  \\\n",
       "0  sample_0000  punchy kick, happy, passionate, scary, eerie, ...   \n",
       "1  sample_0001              e-bass, fun, hip hop, rhythmic patter   \n",
       "2  sample_0002  no percussion, punchy kick, electric guitar, v...   \n",
       "3  sample_0003  acoustic drums, shimmering shakers, male voice...   \n",
       "4  sample_0004  keyboard accompaniment, shimmering cymbals, ba...   \n",
       "\n",
       "                                          prediction  perplexity  \\\n",
       "0  describe this song.\\n\\nThis up-tempo track is ...    8.472451   \n",
       "1  info.\\n\\nThis track starts off with an infecti...    7.610440   \n",
       "2  :\\n\\nIn this hauntingly beautiful composition,...   14.413651   \n",
       "3  only this:\\n**Song Description**\\n\\nIn \"Slow S...   12.282628   \n",
       "4  atmospheric.\\n\\nWhat an intriguing combination...    9.046556   \n",
       "\n",
       "   llm_judge_score                                llm_judge_reasoning  \\\n",
       "0              9.0  The description accurately incorporates all th...   \n",
       "1              5.0  The description is somewhat accurate but lacks...   \n",
       "2              8.0  The description offers a rich and detailed acc...   \n",
       "3              7.0  The description is fairly accurate and coheren...   \n",
       "4              6.0  The description attempts to incorporate most o...   \n",
       "\n",
       "   prediction_length  \n",
       "0                634  \n",
       "1                631  \n",
       "2                691  \n",
       "3                667  \n",
       "4                652  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(merged_predictions['base_random'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8336559",
   "metadata": {},
   "source": [
    "## Analyze overall statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c2a73b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>avg_prediction_length</th>\n",
       "      <th>avg_perplexity</th>\n",
       "      <th>median_perplexity</th>\n",
       "      <th>avg_llm_judge_score</th>\n",
       "      <th>median_llm_judge_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>test</td>\n",
       "      <td>695.348</td>\n",
       "      <td>9.310202</td>\n",
       "      <td>8.858738</td>\n",
       "      <td>5.306</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base_random</td>\n",
       "      <td>test</td>\n",
       "      <td>660.634</td>\n",
       "      <td>11.850457</td>\n",
       "      <td>10.596377</td>\n",
       "      <td>7.111</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base_vae</td>\n",
       "      <td>test</td>\n",
       "      <td>666.776</td>\n",
       "      <td>9.975931</td>\n",
       "      <td>9.486908</td>\n",
       "      <td>7.298</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ft_random</td>\n",
       "      <td>test</td>\n",
       "      <td>446.910</td>\n",
       "      <td>13.391273</td>\n",
       "      <td>12.269531</td>\n",
       "      <td>5.769</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ft_vae</td>\n",
       "      <td>test</td>\n",
       "      <td>385.442</td>\n",
       "      <td>14.550156</td>\n",
       "      <td>13.015625</td>\n",
       "      <td>6.717</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model split  avg_prediction_length  avg_perplexity  \\\n",
       "0    zero_shot  test                695.348        9.310202   \n",
       "1  base_random  test                660.634       11.850457   \n",
       "2     base_vae  test                666.776        9.975931   \n",
       "3    ft_random  test                446.910       13.391273   \n",
       "4       ft_vae  test                385.442       14.550156   \n",
       "\n",
       "   median_perplexity  avg_llm_judge_score  median_llm_judge_score  \n",
       "0           8.858738                5.306                     5.0  \n",
       "1          10.596377                7.111                     7.0  \n",
       "2           9.486908                7.298                     7.0  \n",
       "3          12.269531                5.769                     6.0  \n",
       "4          13.015625                6.717                     7.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Table: model, split, avg_prediction_length, avg_perplexity, median_perplexity, avg_llm_judge_score, median_llm_judge_score\n",
    "summary_stats = []\n",
    "\n",
    "for model, df in merged_predictions.items():\n",
    "    avg_pred_length = df['prediction_length'].mean()\n",
    "    avg_perplexity = df['perplexity'].mean()\n",
    "    median_perplexity = df['perplexity'].median()\n",
    "    avg_llm_judge_score = df['llm_judge_score'].mean()\n",
    "    median_llm_judge_score = df['llm_judge_score'].median()\n",
    "    \n",
    "    summary_stats.append({\n",
    "        'model': model,\n",
    "        'split': split,\n",
    "        'avg_prediction_length': avg_pred_length,\n",
    "        'avg_perplexity': avg_perplexity,\n",
    "        'median_perplexity': median_perplexity,\n",
    "        'avg_llm_judge_score': avg_llm_judge_score,\n",
    "        'median_llm_judge_score': median_llm_judge_score\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "416f730b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c805b761878482daa780f91c5d45480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c876a872734241b28702d6d00ac3e124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69769aafcf34593aa53df67f1f0fc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5895ae4821724395899cdc265c0bdae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbce93f17394f1e85a63d4d00af7708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5282d172930342849db0b5bae2657d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0883c3398f4d6eb83dd568decf0146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3bee1857f94de39a3e190ae1670bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35747e043eeb42cbaa715b4968f88a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee2efd5a45d4683b69361ab698f3f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85598e7629e4205ab9620f6afb47c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b6bb1521eb4975a5fb5d06e5007faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa7cdf10065457e90169f8f4aa45f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2134aea1a1154910881c7ede2879c316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0065d527854070bb95b6e2049ed14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b9e5ed73ee4254ae05efb822b065c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da79436a2e6a481d89bbc364c6fbd4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132315eba2b34c1eb54ff33af7b7f5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686e84b53711439297e964e1269b971f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d623e32b9d2424396a1b5b57fef619f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create huggingface datasets for further analysis\n",
    "for model in models:\n",
    "    df = merged_predictions[model]\n",
    "    hf_dataset = Dataset.from_pandas(df)\n",
    "    hf_dataset_dict = DatasetDict({ 'all': hf_dataset })\n",
    "    hf_dataset_dict.push_to_hub(f\"bsienkiewicz/{model}-caption-inference-dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
