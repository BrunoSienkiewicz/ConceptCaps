{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30674d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5bd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bcf859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "from src.constants import METADATA_CSV_PATH, AUDIO_DATA_PATH, REPO_ID\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "PUSH_TO_HUB = False  # Set to True to push datasets to the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a11317a",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "- Load metadata \n",
    "- Clean and preprocess columns\n",
    "- Push just captions version\n",
    "- Create 3 versions of audio dataset, 10% subset, 25% subset and 100% subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e66ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(METADATA_CSV_PATH)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load concept-to-tags mapping\n",
    "CONCEPTS = json.load(open(\"../data/concepts_to_tags.json\", \"r\"))\n",
    "\n",
    "print(\"Available concept categories:\")\n",
    "for cat, tags in CONCEPTS.items():\n",
    "    print(f\"  {cat}: {len(tags)} tags (e.g., {tags[:3]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reverse mapping\n",
    "TAG_TO_CATEGORY = {}\n",
    "for cat, tags in CONCEPTS.items():\n",
    "    for tag in tags:\n",
    "        TAG_TO_CATEGORY[tag] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836477bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize tags in aspect_list column\n",
    "def categorize_tags(aspect_list):\n",
    "    tags = ast.literal_eval(aspect_list)\n",
    "    aspect_list_categorized = {}\n",
    "    for tag in tags:\n",
    "        category = TAG_TO_CATEGORY.get(tag)\n",
    "        category_columns = f\"{category}_aspects\"\n",
    "        if category_columns not in aspect_list_categorized:\n",
    "            aspect_list_categorized[category_columns] = []\n",
    "        aspect_list_categorized[category_columns].append(tag)\n",
    "    for category in CONCEPTS.keys():\n",
    "        category_columns = f\"{category}_aspects\"\n",
    "        if category_columns not in aspect_list_categorized:\n",
    "            aspect_list_categorized[category_columns] = []\n",
    "    return aspect_list_categorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1793fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.concat(\n",
    "    [\n",
    "        metadata_df,\n",
    "        metadata_df[\"aspect_list\"].apply(categorize_tags).apply(pd.Series),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "metadata_df.rename(columns={\"prediction\": \"caption\"}, inplace=True)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_splits(\n",
    "    df: pd.DataFrame,\n",
    "    train_size: float = 0.7,\n",
    "    valid_size: float = 0.15,\n",
    "    test_size: float = 0.15,\n",
    "    random_state: int = 42\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    train_df, temp_df = train_test_split(\n",
    "        df,\n",
    "        train_size=train_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    valid_ratio = valid_size / (valid_size + test_size)\n",
    "    valid_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        train_size=valid_ratio,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return train_df, valid_df, test_df\n",
    "\n",
    "\n",
    "def create_percentage_subset(\n",
    "    train_df: pd.DataFrame,\n",
    "    percentage: float,\n",
    "    random_state: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    subset_df, _ = train_test_split(\n",
    "        train_df,\n",
    "        train_size=percentage,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    return subset_df\n",
    "\n",
    "def prepare_dataset_dict_with_audio(\n",
    "    train_df: pd.DataFrame,\n",
    "    valid_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    include_audio: bool = False,\n",
    "    subset_name: str = \"100\"\n",
    ") -> DatasetDict:\n",
    "    \"\"\"Prepare dataset with optional audio column.\"\"\"\n",
    "    columns = [\n",
    "        \"id\", \"caption\", \"aspect_list\",\n",
    "        \"genre_aspects\", \"mood_aspects\", \n",
    "        \"instrument_aspects\", \"tempo_aspects\"\n",
    "    ]\n",
    "    \n",
    "    if include_audio:\n",
    "        columns.append(\"file_name\")\n",
    "    \n",
    "    train_clean = train_df[columns].copy()\n",
    "    valid_clean = valid_df[columns].copy()\n",
    "    test_clean = test_df[columns].copy()\n",
    "    \n",
    "    dataset_dict = DatasetDict({\n",
    "        \"train\": Dataset.from_pandas(train_clean, preserve_index=False),\n",
    "        \"validation\": Dataset.from_pandas(valid_clean, preserve_index=False),\n",
    "        \"test\": Dataset.from_pandas(test_clean, preserve_index=False),\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nDataset config '{subset_name}' created:\")\n",
    "    print(f\"  Train: {len(dataset_dict['train'])} samples\")\n",
    "    print(f\"  Valid: {len(dataset_dict['validation'])} samples\")\n",
    "    print(f\"  Test:  {len(dataset_dict['test'])} samples\")\n",
    "    print(f\"  Audio: {include_audio}\")\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d78c55e",
   "metadata": {},
   "source": [
    "## Create subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_no_audio = metadata_df.drop(columns=['file_name'] if 'file_name' in metadata_df.columns else [])\n",
    "\n",
    "train_df_no_audio, valid_df_no_audio, test_df_no_audio = create_balanced_splits(metadata_no_audio)\n",
    "\n",
    "train_10_no_audio = create_percentage_subset(train_df_no_audio, percentage=0.10)\n",
    "valid_10_no_audio = create_percentage_subset(valid_df_no_audio, percentage=0.10)\n",
    "test_10_no_audio = create_percentage_subset(test_df_no_audio, percentage=0.10)\n",
    "\n",
    "train_25_no_audio = create_percentage_subset(train_df_no_audio, percentage=0.25)\n",
    "valid_25_no_audio = create_percentage_subset(valid_df_no_audio, percentage=0.25)\n",
    "test_25_no_audio = create_percentage_subset(test_df_no_audio, percentage=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5584931",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['file_name'] = metadata_df.apply(\n",
    "    lambda row: str(AUDIO_DATA_PATH / row['filename']) if 'filename' in row else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "train_df_audio, valid_df_audio, test_df_audio = create_balanced_splits(metadata_df)\n",
    "\n",
    "train_10_audio = create_percentage_subset(train_df_audio, percentage=0.10)\n",
    "valid_10_audio = create_percentage_subset(valid_df_audio, percentage=0.10)\n",
    "test_10_audio = create_percentage_subset(test_df_audio, percentage=0.10)\n",
    "\n",
    "train_25_audio = create_percentage_subset(train_df_audio, percentage=0.25)\n",
    "valid_25_audio = create_percentage_subset(valid_df_audio, percentage=0.25)\n",
    "test_25_audio = create_percentage_subset(test_df_audio, percentage=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = prepare_dataset_dict_with_audio(\n",
    "    train_df_no_audio, valid_df_no_audio, test_df_no_audio, \n",
    "    include_audio=False, subset_name=\"default\"\n",
    ")\n",
    "dataset_25pct = prepare_dataset_dict_with_audio(\n",
    "    train_25_no_audio, valid_25_no_audio, test_25_no_audio,\n",
    "    include_audio=False, subset_name=\"25pct\"\n",
    ")\n",
    "dataset_10pct = prepare_dataset_dict_with_audio(\n",
    "    train_10_no_audio, valid_10_no_audio, test_10_no_audio,\n",
    "    include_audio=False, subset_name=\"10pct\"\n",
    ")\n",
    "dataset_full_audio = prepare_dataset_dict_with_audio(\n",
    "    train_df_audio, valid_df_audio, test_df_audio,\n",
    "    include_audio=True, subset_name=\"audio\"\n",
    ")\n",
    "dataset_full_audio = dataset_full_audio.cast_column(\"file_name\", Audio())\n",
    "dataset_25pct_audio = prepare_dataset_dict_with_audio(\n",
    "    train_25_audio, valid_25_audio, test_25_audio,\n",
    "    include_audio=True, subset_name=\"25pct-audio\"\n",
    ")\n",
    "dataset_25pct_audio = dataset_25pct_audio.cast_column(\"file_name\", Audio())\n",
    "dataset_10pct_audio = prepare_dataset_dict_with_audio(\n",
    "    train_10_audio, valid_10_audio, test_10_audio,\n",
    "    include_audio=True, subset_name=\"10pct-audio\"\n",
    ")\n",
    "dataset_10pct_audio = dataset_10pct_audio.cast_column(\"file_name\", Audio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97045330",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PUSH_TO_HUB:\n",
    "    api = HfApi()\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=\"../DATASET_CARD.md\",\n",
    "        path_in_repo=\"README.md\",\n",
    "        repo_id=REPO_ID,\n",
    "        repo_type=\"dataset\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PUSH_TO_HUB:\n",
    "    print(f\"\\nPushing all configurations to {REPO_ID}...\")\n",
    "    \n",
    "    print(\"Pushing 'default' configuration...\")\n",
    "    dataset_full.push_to_hub(REPO_ID, config_name=\"default\", private=False)\n",
    "    \n",
    "    print(\"Pushing '25pct' configuration...\")\n",
    "    dataset_25pct.push_to_hub(REPO_ID, config_name=\"25pct\", private=False)\n",
    "    \n",
    "    print(\"Pushing '10pct' configuration...\")\n",
    "    dataset_10pct.push_to_hub(REPO_ID, config_name=\"10pct\", private=False)\n",
    "    \n",
    "    print(\"Pushing 'audio' configuration (full with audio)...\")\n",
    "    dataset_full_audio.push_to_hub(REPO_ID, config_name=\"audio\", private=False)\n",
    "    \n",
    "    print(\"Pushing '25pct-audio' configuration...\")\n",
    "    dataset_25pct_audio.push_to_hub(REPO_ID, config_name=\"25pct-audio\", private=False)\n",
    "    \n",
    "    print(\"Pushing '10pct-audio' configuration...\")\n",
    "    dataset_10pct_audio.push_to_hub(REPO_ID, config_name=\"10pct-audio\", private=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concept-caps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
