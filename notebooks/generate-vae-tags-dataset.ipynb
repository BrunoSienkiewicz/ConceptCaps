{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9624fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# import lightning as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import ast\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "# pl.seed_everything(seed)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff4b28",
   "metadata": {},
   "source": [
    "## Define Tag Categories\n",
    "\n",
    "Define all possible tags for each category based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ee1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXONOMY = json.load(open(\"../data/concepts_to_tags.json\", \"r\"))\n",
    "\n",
    "CATEGORIES = list(TAXONOMY.keys())\n",
    "\n",
    "# Reverse map for easy lookup (tag -> category)\n",
    "TAG_TO_CATEGORY = {}\n",
    "for cat, tags in TAXONOMY.items():\n",
    "    for tag in tags:\n",
    "        TAG_TO_CATEGORY[tag] = cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f71783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Input Dimension: 400\n"
     ]
    }
   ],
   "source": [
    "tag_to_idx = {}\n",
    "idx_to_tag = {}\n",
    "cat_ranges = {} # Stores start/end index for each category\n",
    "\n",
    "current_idx = 0\n",
    "for cat in CATEGORIES:\n",
    "    start = current_idx\n",
    "    for tag in TAXONOMY[cat]:\n",
    "        tag_to_idx[tag] = current_idx\n",
    "        idx_to_tag[current_idx] = (cat, tag)\n",
    "        current_idx += 1\n",
    "    cat_ranges[cat] = (start, current_idx)\n",
    "\n",
    "TOTAL_INPUT_DIM = current_idx\n",
    "print(f\"Total Input Dimension: {TOTAL_INPUT_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1e75e",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6227ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_multilabel(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates a Multi-Hot vector for every song.\n",
    "    Example: [0, 1, 0, 1, 1, ...] where 1 means the tag is present.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        raw_tags = ast.literal_eval(row['aspect_list'])\n",
    "        raw_tags = [t.lower() for t in raw_tags]\n",
    "            \n",
    "        # Create Zero Vector\n",
    "        vector = np.zeros(TOTAL_INPUT_DIM, dtype=np.float32)\n",
    "        has_data = False\n",
    "        \n",
    "        for tag in raw_tags:\n",
    "            if tag in tag_to_idx:\n",
    "                idx = tag_to_idx[tag]\n",
    "                vector[idx] = 1.0\n",
    "                has_data = True\n",
    "        \n",
    "        # Only keep records that have at least one valid tag\n",
    "        if has_data:\n",
    "            processed_data.append(vector)\n",
    "            \n",
    "    return np.array(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6dd7410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"google/MusicCaps\", split=\"train\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e6cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data shape: (5163, 400)\n"
     ]
    }
   ],
   "source": [
    "data = process_data_multilabel(df)\n",
    "print(f\"Processed data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173cf11d",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4860cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelVAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=32, hidden_dim=128):\n",
    "        super(MultiLabelVAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, input_dim) \n",
    "        \n",
    "        # Dropout for the \"Denoising\" part (applied to input)\n",
    "        self.input_dropout = nn.Dropout(p=0.3) \n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc2_mu(h1), self.fc2_logvar(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, temperature=1.0):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        logits = self.fc4(h3)\n",
    "        return torch.sigmoid(logits / temperature)\n",
    "\n",
    "    def forward(self, x, temperature=1.0):\n",
    "        # Apply dropout to inputs during training -> forces model to learn correlations\n",
    "        x_noisy = self.input_dropout(x)\n",
    "        mu, logvar = self.encode(x_noisy)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z, temperature=temperature)\n",
    "        return recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c306c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = TOTAL_INPUT_DIM\n",
    "latent_dim = 32\n",
    "hidden_dim = 128\n",
    "batch_size = 64\n",
    "num_epochs = 300\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed41eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, Optimizer, Loss Function\n",
    "model = MultiLabelVAE(input_dim, latent_dim, hidden_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "bce_loss_fn = nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be82a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    BCE = bce_loss_fn(recon_x, x)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aeb64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataLoader\n",
    "dataset = torch.utils.data.TensorDataset(torch.tensor(data))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fca319ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:   4%|▎         | 11/300 [00:01<00:43,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Loss: 21.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:   7%|▋         | 21/300 [00:03<00:40,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300], Loss: 21.2515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  10%|█         | 31/300 [00:04<00:39,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Loss: 20.4310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  14%|█▎        | 41/300 [00:06<00:37,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/300], Loss: 19.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  17%|█▋        | 51/300 [00:07<00:35,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Loss: 19.5690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  20%|██        | 61/300 [00:09<00:33,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/300], Loss: 19.1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  24%|██▎       | 71/300 [00:10<00:32,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/300], Loss: 18.7781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  27%|██▋       | 81/300 [00:12<00:32,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/300], Loss: 18.5538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  30%|███       | 91/300 [00:13<00:30,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/300], Loss: 18.4329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  34%|███▎      | 101/300 [00:15<00:29,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/300], Loss: 18.3067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  37%|███▋      | 111/300 [00:16<00:27,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/300], Loss: 18.2259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  40%|████      | 121/300 [00:17<00:26,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/300], Loss: 18.1251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  44%|████▎     | 131/300 [00:19<00:24,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/300], Loss: 18.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  47%|████▋     | 141/300 [00:20<00:23,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/300], Loss: 18.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  50%|█████     | 151/300 [00:22<00:21,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/300], Loss: 17.9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  54%|█████▎    | 161/300 [00:23<00:21,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/300], Loss: 17.9792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  57%|█████▋    | 171/300 [00:25<00:18,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [170/300], Loss: 17.8423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  60%|██████    | 181/300 [00:26<00:17,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/300], Loss: 17.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  64%|██████▎   | 191/300 [00:28<00:16,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/300], Loss: 17.8484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  67%|██████▋   | 201/300 [00:29<00:14,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/300], Loss: 17.7574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  70%|███████   | 211/300 [00:31<00:12,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [210/300], Loss: 17.7585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  74%|███████▎  | 221/300 [00:32<00:11,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [220/300], Loss: 17.7318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  77%|███████▋  | 231/300 [00:34<00:11,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [230/300], Loss: 17.6845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  80%|████████  | 241/300 [00:35<00:08,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [240/300], Loss: 17.6235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  84%|████████▎ | 251/300 [00:37<00:07,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [250/300], Loss: 17.6622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  87%|████████▋ | 261/300 [00:38<00:05,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [260/300], Loss: 17.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  90%|█████████ | 271/300 [00:40<00:04,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [270/300], Loss: 17.6376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  94%|█████████▎| 281/300 [00:41<00:02,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [280/300], Loss: 17.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE:  97%|█████████▋| 291/300 [00:43<00:01,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [290/300], Loss: 17.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE: 100%|██████████| 300/300 [00:44<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/300], Loss: 17.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training VAE\"):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        inputs = batch[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(inputs)\n",
    "        loss = vae_loss(recon_batch, inputs, mu, logvar)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"../models/multilabel_vae.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38685f51",
   "metadata": {},
   "source": [
    "## Generate tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5e71d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "      <th>genre_tags</th>\n",
       "      <th>mood_tags</th>\n",
       "      <th>instrument_tags</th>\n",
       "      <th>aspect_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>track_0007391</td>\n",
       "      <td>['genre---electronic', 'genre---pop', 'instrum...</td>\n",
       "      <td>[electronic, pop]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[bass, drums, guitar, keyboard]</td>\n",
       "      <td>[drums, bass, guitar, electronic, emotional, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track_0015161</td>\n",
       "      <td>['genre---instrumentalpop', 'genre---pop', 'ge...</td>\n",
       "      <td>[pop, rock]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[bass, drums]</td>\n",
       "      <td>[drums, bass, rock, emotional, pop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>track_0015166</td>\n",
       "      <td>['genre---dance', 'genre---electronic', 'genre...</td>\n",
       "      <td>[dance, electronic, pop, techno]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[bass]</td>\n",
       "      <td>[bass, electronic, dance, techno, emotional, pop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>track_0015167</td>\n",
       "      <td>['genre---chillout', 'genre---easylistening', ...</td>\n",
       "      <td>[electronic, pop]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[bass, violin]</td>\n",
       "      <td>[bass, electronic, emotional, pop, violin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>track_0015169</td>\n",
       "      <td>['genre---electronic', 'genre---instrumentalpo...</td>\n",
       "      <td>[electronic, pop]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[bass, drums]</td>\n",
       "      <td>[drums, bass, electronic, emotional, pop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>track_1420702</td>\n",
       "      <td>['genre---dance', 'genre---easylistening', 'ge...</td>\n",
       "      <td>[dance]</td>\n",
       "      <td>[funk, happy]</td>\n",
       "      <td>[bass, drums, keyboard]</td>\n",
       "      <td>[drums, bass, dance, funk, keyboard, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>track_1420704</td>\n",
       "      <td>['genre---dance', 'genre---easylistening', 'in...</td>\n",
       "      <td>[dance]</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>[bass, drums, keyboard]</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>track_1420705</td>\n",
       "      <td>['genre---dance', 'genre---easylistening', 'in...</td>\n",
       "      <td>[dance]</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>[bass, drums, keyboard]</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>track_1420706</td>\n",
       "      <td>['genre---dance', 'genre---easylistening', 'in...</td>\n",
       "      <td>[dance]</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>[bass, drums, keyboard]</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>track_1420707</td>\n",
       "      <td>['genre---chillout', 'genre---dance', 'genre--...</td>\n",
       "      <td>[dance, house]</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>[bass, drums, keyboard]</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy, house]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2041 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               tags  \\\n",
       "0     track_0007391  ['genre---electronic', 'genre---pop', 'instrum...   \n",
       "1     track_0015161  ['genre---instrumentalpop', 'genre---pop', 'ge...   \n",
       "2     track_0015166  ['genre---dance', 'genre---electronic', 'genre...   \n",
       "3     track_0015167  ['genre---chillout', 'genre---easylistening', ...   \n",
       "4     track_0015169  ['genre---electronic', 'genre---instrumentalpo...   \n",
       "...             ...                                                ...   \n",
       "2036  track_1420702  ['genre---dance', 'genre---easylistening', 'ge...   \n",
       "2037  track_1420704  ['genre---dance', 'genre---easylistening', 'in...   \n",
       "2038  track_1420705  ['genre---dance', 'genre---easylistening', 'in...   \n",
       "2039  track_1420706  ['genre---dance', 'genre---easylistening', 'in...   \n",
       "2040  track_1420707  ['genre---chillout', 'genre---dance', 'genre--...   \n",
       "\n",
       "                            genre_tags      mood_tags  \\\n",
       "0                    [electronic, pop]    [emotional]   \n",
       "1                          [pop, rock]    [emotional]   \n",
       "2     [dance, electronic, pop, techno]    [emotional]   \n",
       "3                    [electronic, pop]    [emotional]   \n",
       "4                    [electronic, pop]    [emotional]   \n",
       "...                                ...            ...   \n",
       "2036                           [dance]  [funk, happy]   \n",
       "2037                           [dance]        [happy]   \n",
       "2038                           [dance]        [happy]   \n",
       "2039                           [dance]        [happy]   \n",
       "2040                    [dance, house]        [happy]   \n",
       "\n",
       "                      instrument_tags  \\\n",
       "0     [bass, drums, guitar, keyboard]   \n",
       "1                       [bass, drums]   \n",
       "2                              [bass]   \n",
       "3                      [bass, violin]   \n",
       "4                       [bass, drums]   \n",
       "...                               ...   \n",
       "2036          [bass, drums, keyboard]   \n",
       "2037          [bass, drums, keyboard]   \n",
       "2038          [bass, drums, keyboard]   \n",
       "2039          [bass, drums, keyboard]   \n",
       "2040          [bass, drums, keyboard]   \n",
       "\n",
       "                                            aspect_list  \n",
       "0     [drums, bass, guitar, electronic, emotional, p...  \n",
       "1                   [drums, bass, rock, emotional, pop]  \n",
       "2     [bass, electronic, dance, techno, emotional, pop]  \n",
       "3            [bass, electronic, emotional, pop, violin]  \n",
       "4             [drums, bass, electronic, emotional, pop]  \n",
       "...                                                 ...  \n",
       "2036        [drums, bass, dance, funk, keyboard, happy]  \n",
       "2037              [drums, bass, dance, keyboard, happy]  \n",
       "2038              [drums, bass, dance, keyboard, happy]  \n",
       "2039              [drums, bass, dance, keyboard, happy]  \n",
       "2040       [drums, bass, dance, keyboard, happy, house]  \n",
       "\n",
       "[2041 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/mtg_jamendo/autotagging_top50tags_processed_cleaned.csv\")\n",
    "df['aspect_list'] = df['aspect_list'].apply(ast.literal_eval)\n",
    "df['instrument_tags'] = df['instrument_tags'].apply(ast.literal_eval)\n",
    "df['genre_tags'] = df['genre_tags'].apply(ast.literal_eval)\n",
    "df['mood_tags'] = df['mood_tags'].apply(ast.literal_eval)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1cb4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelVAE(\n",
       "  (fc1): Linear(in_features=400, out_features=128, bias=True)\n",
       "  (fc2_mu): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (fc2_logvar): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=400, bias=True)\n",
       "  (input_dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiLabelVAE(input_dim, latent_dim, hidden_dim).to(device)\n",
    "model.load_state_dict(torch.load(\"../models/multilabel_vae.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8dfa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tags(model, seed_tags, requests, temperature=1.0):\n",
    "    \"\"\"\n",
    "    seeds: List of tags we ALREADY have (e.g. ['rock', 'guitar'])\n",
    "    requests: Dict of how many tags we want per category (e.g. {'instrument': 2, 'mood': 1})\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # 1. Build the Input Vector from Seeds\n",
    "    input_vec = torch.zeros(1, TOTAL_INPUT_DIM).to(device)\n",
    "    \n",
    "    \n",
    "    # Fill in the knowns\n",
    "    for tag in seed_tags:\n",
    "        if tag in tag_to_idx:\n",
    "            input_vec[0, tag_to_idx[tag]] = 1.0\n",
    "        else:\n",
    "            print(f\"Warning: Seed tag '{tag}' not in taxonomy.\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 2. Encode to get the Latent Vibe (z)\n",
    "        # Note: We don't use dropout here; we want the model to use all clues we gave it.\n",
    "        mu, logvar = model.encode(input_vec)\n",
    "        z = model.reparameterize(mu, logvar)\n",
    "        \n",
    "        # 3. Decode to get probabilities for EVERYTHING\n",
    "        # Output shape: [1, Total_Dim] (Values 0.0 to 1.0)\n",
    "        probs = model.decode(z, temperature=temperature)[0] \n",
    "        \n",
    "        # 4. Extract Top-K for requested categories\n",
    "        results = {}\n",
    "        \n",
    "        for category, count in requests.items():\n",
    "            if count <= 0:\n",
    "                results[f\"generated_{category}_tags\"] = []\n",
    "                continue\n",
    "\n",
    "            start, end = cat_ranges[category]\n",
    "            \n",
    "            # Slice the probabilities relevant to this category\n",
    "            cat_probs = probs[start:end]\n",
    "            \n",
    "            # Get Top K indices for this slice\n",
    "            # We ask for count + len(seeds) just in case the model predicts the seed tag again\n",
    "            top_k_vals, top_k_indices = torch.topk(cat_probs, k=count + 5)\n",
    "            \n",
    "            # Convert slice-indices back to global-indices, then to strings\n",
    "            found_tags = []\n",
    "            for i in range(len(top_k_indices)):\n",
    "                local_idx = top_k_indices[i].item()\n",
    "                global_idx = start + local_idx\n",
    "                tag_name = idx_to_tag[global_idx][1]\n",
    "                \n",
    "                # Don't return tags we already provided as seeds\n",
    "                if tag_name not in seed_tags:\n",
    "                    found_tags.append(tag_name)\n",
    "                \n",
    "                if len(found_tags) == count:\n",
    "                    break\n",
    "            \n",
    "            results[f\"generated_{category}_tags\"] = found_tags\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b7d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(idx: int, tags_per_category: dict[str, int], temperature=1.0):\n",
    "    row = df.iloc[idx]\n",
    "    seed_tags = []\n",
    "    for category in ['genre', 'instrument', 'mood', 'tempo']:\n",
    "        if len(row[f\"{category}_tags\"]) > 1:\n",
    "            seed_tags.append(np.random.choice(row[f\"{category}_tags\"]))\n",
    "            tags_per_category[category] = tags_per_category.get(category, 1) - 1\n",
    "        \n",
    "    generated_tags = generate_tags(model, seed_tags, tags_per_category)\n",
    "    _generated_tags = []\n",
    "    for gtags in generated_tags.values():\n",
    "        _generated_tags.extend(gtags)\n",
    "\n",
    "    res_entry = {\n",
    "        'id': row['id'],\n",
    "        'original_aspect_list': row['aspect_list'],\n",
    "        'aspect_list': seed_tags + _generated_tags,\n",
    "        **generated_tags\n",
    "    }\n",
    "    return pd.DataFrame([res_entry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce4f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\n",
    "    \"tempo\",\n",
    "    \"genre\",\n",
    "    \"mood\",\n",
    "    \"instrument\"\n",
    "]\n",
    "N_CATEGORIES = len(CATEGORIES)\n",
    "N_SAMPLES_TO_GENERATE = len(df)\n",
    "\n",
    "# --- 1. SYNTHETIC DATA GENERATION (Replace with your actual data) ---\n",
    "# We simulate a dataset where tag counts are discrete and correlated.\n",
    "# Max counts are defined for simulation purposes.\n",
    "MAX_COUNTS = {\n",
    "    \"tempo\": 4,\n",
    "    \"genre\": 4, \n",
    "    \"mood\": 5, \n",
    "    \"instrument\": 6, \n",
    "}\n",
    "MEANS = {\n",
    "    \"tempo\": 1.24,\n",
    "    \"genre\": 1.46, \n",
    "    \"mood\": 1.71, \n",
    "    \"instrument\": 2.48,\n",
    "}\n",
    "VARIANCES = {\n",
    "    \"tempo\": 0.6,\n",
    "    \"genre\": 0.87,\n",
    "    \"mood\": 1.09,\n",
    "    \"instrument\": 1.37,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70e0d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_correlated_data(n_records):\n",
    "    \"\"\"\n",
    "    Creates synthetic discrete count data that serves as the 'real' dataset.\n",
    "    This step is highly important: it determines the statistics (R and ECDFs)\n",
    "    that the Copula will try to match.\n",
    "    \"\"\"\n",
    "    print(\"--- 1. Generating Synthetic Data ---\")\n",
    "\n",
    "    # Define the desired correlation matrix (e.g., high correlation between Genre and Instrument)\n",
    "    # This represents your calculated correlation matrix R.\n",
    "    correlation_matrix = np.array([\n",
    "        [1.0, 0.2, 0.1, 0.03],  # Tempo\n",
    "        [0.2, 1.0, 0.3, -0.01],  # Genre\n",
    "        [0.1, 0.12, 1.0, -0.05],  # Mood\n",
    "        [0.03, -0.01, -0.05, 1.0]   # Instrument\n",
    "    ])\n",
    "\n",
    "    # Generate correlated continuous data (Multivariate Normal)\n",
    "    mean = np.zeros(N_CATEGORIES)\n",
    "    z_continuous = multivariate_normal.rvs(mean=mean, cov=correlation_matrix, size=n_records)\n",
    "\n",
    "    data = np.zeros((n_records, N_CATEGORIES), dtype=int)\n",
    "    \n",
    "    # Transform continuous data into discrete counts based on desired marginals\n",
    "    # (using inverse CDF of an arbitrary discrete distribution for simulation)\n",
    "    # This simulates your real-world data having specific tag count distributions\n",
    "    for i, cat in enumerate(CATEGORIES):\n",
    "        max_c = MAX_COUNTS[cat]\n",
    "        # Simulate log normal-like distribution for counts\n",
    "        mu = np.log(MEANS[cat]**2 / np.sqrt(MEANS[cat]**2 + VARIANCES[cat]))\n",
    "        sigma = np.sqrt(np.log(1 + VARIANCES[cat] / MEANS[cat]**2))\n",
    "        # Create discrete probability distribution\n",
    "        x = np.arange(1, max_c + 1)\n",
    "        p = (1 / (x * sigma * np.sqrt(2 * np.pi)))\n",
    "        p *= np.exp(- (np.log(x) - mu)**2 / (2 * sigma**2))\n",
    "        p /= p.sum()  # Normalize to sum to 1\n",
    "        \n",
    "        # Convert continuous z (uniform quantile) to discrete count (inverse CDF)\n",
    "        uniform_quantiles = norm.cdf(z_continuous[:, i])\n",
    "        \n",
    "        # Quantile mapping for a simple discrete distribution\n",
    "        counts = np.digitize(uniform_quantiles, np.cumsum(p[:-1])) + 1\n",
    "        data[:, i] = np.clip(counts, 1, max_c)\n",
    "\n",
    "    print(f\"Synthetic Data Shape: {data.shape}\")\n",
    "    print(f\"Calculated Correlation of Synthetic Data:\\n{np.corrcoef(data.T).round(2)}\")\n",
    "    return data, correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cda91803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Generating Synthetic Data ---\n",
      "Synthetic Data Shape: (2041, 4)\n",
      "Calculated Correlation of Synthetic Data:\n",
      "[[ 1.    0.14  0.09 -0.01]\n",
      " [ 0.14  1.    0.21  0.  ]\n",
      " [ 0.09  0.21  1.   -0.06]\n",
      " [-0.01  0.   -0.06  1.  ]]\n",
      "[[2 2 4 6]\n",
      " [2 1 2 2]\n",
      " [1 1 2 2]\n",
      " ...\n",
      " [2 1 1 2]\n",
      " [1 1 1 1]\n",
      " [1 2 2 3]]\n"
     ]
    }
   ],
   "source": [
    "data, _ = generate_synthetic_correlated_data(N_SAMPLES_TO_GENERATE)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb7173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_aspect_list</th>\n",
       "      <th>aspect_list</th>\n",
       "      <th>generated_tempo_tags</th>\n",
       "      <th>generated_genre_tags</th>\n",
       "      <th>generated_mood_tags</th>\n",
       "      <th>generated_instrument_tags</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>track_0007391</td>\n",
       "      <td>[drums, bass, guitar, electronic, emotional, p...</td>\n",
       "      <td>[electronic, guitar, emotional, slow tempo, ca...</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[calming, passionate]</td>\n",
       "      <td>[flat male vocal]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track_0015161</td>\n",
       "      <td>[drums, bass, rock, emotional, pop]</td>\n",
       "      <td>[rock, bass, emotional, medium tempo, intense,...</td>\n",
       "      <td>[medium tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[intense, epic, dramatic]</td>\n",
       "      <td>[electric guitar, orchestra]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>track_0015166</td>\n",
       "      <td>[bass, electronic, dance, techno, emotional, pop]</td>\n",
       "      <td>[pop, bass, emotional, medium tempo, movie mus...</td>\n",
       "      <td>[medium tempo]</td>\n",
       "      <td>[movie music]</td>\n",
       "      <td>[dramatic]</td>\n",
       "      <td>[electric guitar, no singer, electronic drums]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>track_0015167</td>\n",
       "      <td>[bass, electronic, emotional, pop, violin]</td>\n",
       "      <td>[pop, violin, emotional, medium tempo, happy]</td>\n",
       "      <td>[medium tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>track_0015169</td>\n",
       "      <td>[drums, bass, electronic, emotional, pop]</td>\n",
       "      <td>[electronic, bass, emotional, uptempo, acousti...</td>\n",
       "      <td>[uptempo, acoustic rhythm guitar chords]</td>\n",
       "      <td>[classical, jazz]</td>\n",
       "      <td>[passionate]</td>\n",
       "      <td>[flat male vocal]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>track_1420702</td>\n",
       "      <td>[drums, bass, dance, funk, keyboard, happy]</td>\n",
       "      <td>[dance, drums, happy, upbeat, movie music, pla...</td>\n",
       "      <td>[upbeat]</td>\n",
       "      <td>[movie music]</td>\n",
       "      <td>[playful]</td>\n",
       "      <td>[percussion, no singer]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>track_1420704</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[dance, bass, happy, upbeat, pop, fun, claps]</td>\n",
       "      <td>[upbeat]</td>\n",
       "      <td>[pop]</td>\n",
       "      <td>[fun]</td>\n",
       "      <td>[claps]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>track_1420705</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[dance, drums, happy, fast tempo, country musi...</td>\n",
       "      <td>[fast tempo]</td>\n",
       "      <td>[country music, folk music]</td>\n",
       "      <td>[cheerful, playful, festive]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>track_1420706</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[dance, drums, happy, medium tempo, country mu...</td>\n",
       "      <td>[medium tempo]</td>\n",
       "      <td>[country music]</td>\n",
       "      <td>[playful]</td>\n",
       "      <td>[electric guitar]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>track_1420707</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy, house]</td>\n",
       "      <td>[dance, drums, happy, fast tempo, playful, ene...</td>\n",
       "      <td>[fast tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[playful, energetic]</td>\n",
       "      <td>[no singer, percussion, male voice]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10205 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                               original_aspect_list  \\\n",
       "0      track_0007391  [drums, bass, guitar, electronic, emotional, p...   \n",
       "1      track_0015161                [drums, bass, rock, emotional, pop]   \n",
       "2      track_0015166  [bass, electronic, dance, techno, emotional, pop]   \n",
       "3      track_0015167         [bass, electronic, emotional, pop, violin]   \n",
       "4      track_0015169          [drums, bass, electronic, emotional, pop]   \n",
       "...              ...                                                ...   \n",
       "10200  track_1420702        [drums, bass, dance, funk, keyboard, happy]   \n",
       "10201  track_1420704              [drums, bass, dance, keyboard, happy]   \n",
       "10202  track_1420705              [drums, bass, dance, keyboard, happy]   \n",
       "10203  track_1420706              [drums, bass, dance, keyboard, happy]   \n",
       "10204  track_1420707       [drums, bass, dance, keyboard, happy, house]   \n",
       "\n",
       "                                             aspect_list  \\\n",
       "0      [electronic, guitar, emotional, slow tempo, ca...   \n",
       "1      [rock, bass, emotional, medium tempo, intense,...   \n",
       "2      [pop, bass, emotional, medium tempo, movie mus...   \n",
       "3          [pop, violin, emotional, medium tempo, happy]   \n",
       "4      [electronic, bass, emotional, uptempo, acousti...   \n",
       "...                                                  ...   \n",
       "10200  [dance, drums, happy, upbeat, movie music, pla...   \n",
       "10201      [dance, bass, happy, upbeat, pop, fun, claps]   \n",
       "10202  [dance, drums, happy, fast tempo, country musi...   \n",
       "10203  [dance, drums, happy, medium tempo, country mu...   \n",
       "10204  [dance, drums, happy, fast tempo, playful, ene...   \n",
       "\n",
       "                           generated_tempo_tags         generated_genre_tags  \\\n",
       "0                                  [slow tempo]                           []   \n",
       "1                                [medium tempo]                           []   \n",
       "2                                [medium tempo]                [movie music]   \n",
       "3                                [medium tempo]                           []   \n",
       "4      [uptempo, acoustic rhythm guitar chords]            [classical, jazz]   \n",
       "...                                         ...                          ...   \n",
       "10200                                  [upbeat]                [movie music]   \n",
       "10201                                  [upbeat]                        [pop]   \n",
       "10202                              [fast tempo]  [country music, folk music]   \n",
       "10203                            [medium tempo]              [country music]   \n",
       "10204                              [fast tempo]                           []   \n",
       "\n",
       "                generated_mood_tags  \\\n",
       "0             [calming, passionate]   \n",
       "1         [intense, epic, dramatic]   \n",
       "2                        [dramatic]   \n",
       "3                           [happy]   \n",
       "4                      [passionate]   \n",
       "...                             ...   \n",
       "10200                     [playful]   \n",
       "10201                         [fun]   \n",
       "10202  [cheerful, playful, festive]   \n",
       "10203                     [playful]   \n",
       "10204          [playful, energetic]   \n",
       "\n",
       "                            generated_instrument_tags  temperature  \n",
       "0                                   [flat male vocal]          0.5  \n",
       "1                        [electric guitar, orchestra]          0.5  \n",
       "2      [electric guitar, no singer, electronic drums]          0.5  \n",
       "3                                                  []          0.5  \n",
       "4                                   [flat male vocal]          0.5  \n",
       "...                                               ...          ...  \n",
       "10200                         [percussion, no singer]          1.5  \n",
       "10201                                         [claps]          1.5  \n",
       "10202                                              []          1.5  \n",
       "10203                               [electric guitar]          1.5  \n",
       "10204             [no singer, percussion, male voice]          1.5  \n",
       "\n",
       "[10205 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatures = [1.0, 1.5, 2, 2.5, 3]\n",
    "\n",
    "res_df = pd.DataFrame()\n",
    "\n",
    "for temp in tqdm(temperatures):\n",
    "    for idx in tqdm(range(N_SAMPLES_TO_GENERATE), leave=False):\n",
    "        num_tags_for_category = {\n",
    "            \"tempo\": data[idx, 0],\n",
    "            \"genre\": data[idx, 1],\n",
    "            \"mood\": data[idx, 2],\n",
    "            \"instrument\": data[idx, 3],\n",
    "        }\n",
    "        temp_df = generate_df(idx, tags_per_category=num_tags_for_category, temperature=temp)\n",
    "        temp_df['temperature'] = temp\n",
    "        res_df = pd.concat([res_df, temp_df], ignore_index=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f88e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort aspect list column and deduplicate tag combinations\n",
    "res_df['aspect_list'] = res_df['aspect_list'].apply(lambda x: sorted(list(set(x))))\n",
    "res_df = res_df.drop_duplicates(subset=['aspect_list']).reset_index(drop=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add surrogate key based on track_id and temperature\n",
    "import hashlib\n",
    "def generate_surrogate_key(track_id: str, temperature: float) -> str:\n",
    "    key_str = f\"{track_id}_{temperature}\"\n",
    "    return hashlib.md5(key_str.encode()).hexdigest()\n",
    "\n",
    "res_df['surrogate_key'] = res_df.apply(lambda row: generate_surrogate_key(row['id'], row['temperature']), axis=1)\n",
    "res_df.drop(columns=['id'], inplace=True)\n",
    "res_df.rename(columns={'surrogate_key': 'id'}, inplace=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680d5ad",
   "metadata": {},
   "source": [
    "## Push to Hugginface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2dce411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_valid = train_test_split(res_df, test_size=0.1, random_state=42)\n",
    "df_valid, df_test = train_test_split(df_valid, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ee617a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"../data/vae_mtg_tags\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_train.to_csv(output_dir / \"train.csv\", index=False)\n",
    "df_valid.to_csv(output_dir / \"validation.csv\", index=False)\n",
    "df_test.to_csv(output_dir / \"test.csv\", index=False)\n",
    "all_df = pd.concat([df_train, df_valid, df_test])\n",
    "all_df.to_csv(output_dir / \"all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a3829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efb5acc27d145edadf7b3d48c2514ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce089d42098404bac72fb00ad64b3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3a535167aa4c2cb1712087e4d61a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9908f640fa754eb1a22436ccddd41a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82657d45c9aa434e8fe3617dbcc3d093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0039644e6407445dae6d3e00010cf03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb9838b8eea47e5904085e7cb253555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e00fda631a4997954ffaac8da3ce79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d41b567d50c4e269e0e2362adb6524c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95a412eab3f4e4b8b767ac7d7a32405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854b15f622324c0c9ed11db4f3a265fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e33ffc26f9c4dd09553fc599741902c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4dd9a684b24653a3364eae97ff57f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed4252bdf9b47bd9e18ef61e7e32720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d354cce344e42af8617be5bad2d1b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212fa698bd3740dba0484902b4a604f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/813 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/bsienkiewicz/mtg_causal_tags_dataset/commit/c389f6cc328f38da916c0f4400f9b3467d8c25e9', commit_message='Upload dataset', commit_description='', oid='c389f6cc328f38da916c0f4400f9b3467d8c25e9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/bsienkiewicz/mtg_causal_tags_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='bsienkiewicz/mtg_causal_tags_dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": str(output_dir / \"train.csv\"),\n",
    "    \"validation\": str(output_dir / \"validation.csv\"),\n",
    "    \"test\": str(output_dir / \"test.csv\")\n",
    "}\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "dataset.push_to_hub(\"bsienkiewicz/mtg_vae_tags_dataset\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
