{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9624fce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import ast\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff4b28",
   "metadata": {},
   "source": [
    "## Define Tag Categories\n",
    "\n",
    "Define all possible tags for each category based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ee1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXONOMY = json.load(open(\"../data/concepts_to_tags.json\", \"r\"))\n",
    "\n",
    "CATEGORIES = list(TAXONOMY.keys())\n",
    "\n",
    "# Reverse map for easy lookup (tag -> category)\n",
    "TAG_TO_CATEGORY = {}\n",
    "for cat, tags in TAXONOMY.items():\n",
    "    for tag in tags:\n",
    "        TAG_TO_CATEGORY[tag] = cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f71783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Input Dimension: 200\n"
     ]
    }
   ],
   "source": [
    "tag_to_idx = {}\n",
    "idx_to_tag = {}\n",
    "cat_ranges = {} # Stores start/end index for each category\n",
    "\n",
    "current_idx = 0\n",
    "for cat in CATEGORIES:\n",
    "    start = current_idx\n",
    "    for tag in TAXONOMY[cat]:\n",
    "        tag_to_idx[tag] = current_idx\n",
    "        idx_to_tag[current_idx] = (cat, tag)\n",
    "        current_idx += 1\n",
    "    cat_ranges[cat] = (start, current_idx)\n",
    "\n",
    "TOTAL_INPUT_DIM = current_idx\n",
    "print(f\"Total Input Dimension: {TOTAL_INPUT_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1e75e",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6227ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_multilabel(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates a Multi-Hot vector for every song.\n",
    "    Example: [0, 1, 0, 1, 1, ...] where 1 means the tag is present.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        raw_tags = ast.literal_eval(row['aspect_list'])\n",
    "        raw_tags = [t.lower() for t in raw_tags]\n",
    "            \n",
    "        # Create Zero Vector\n",
    "        vector = np.zeros(TOTAL_INPUT_DIM, dtype=np.float32)\n",
    "        has_data = False\n",
    "        \n",
    "        for tag in raw_tags:\n",
    "            if tag in tag_to_idx:\n",
    "                idx = tag_to_idx[tag]\n",
    "                vector[idx] = 1.0\n",
    "                has_data = True\n",
    "        \n",
    "        # Only keep records that have at least one valid tag\n",
    "        if has_data:\n",
    "            processed_data.append(vector)\n",
    "            \n",
    "    return np.array(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6dd7410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"google/MusicCaps\", split=\"train\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e6cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data shape: (5046, 200)\n"
     ]
    }
   ],
   "source": [
    "data = process_data_multilabel(df)\n",
    "print(f\"Processed data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173cf11d",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4860cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelVAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=32, hidden_dim=128):\n",
    "        super(MultiLabelVAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, input_dim) \n",
    "        \n",
    "        # Dropout for the \"Denoising\" part (applied to input)\n",
    "        self.input_dropout = nn.Dropout(p=0.3) \n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc2_mu(h1), self.fc2_logvar(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, temperature=1.0):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        logits = self.fc4(h3)\n",
    "        return torch.sigmoid(logits / temperature)\n",
    "\n",
    "    def forward(self, x, temperature=1.0):\n",
    "        # Apply dropout to inputs during training -> forces model to learn correlations\n",
    "        x_noisy = self.input_dropout(x)\n",
    "        mu, logvar = self.encode(x_noisy)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z, temperature=temperature)\n",
    "        return recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7c306c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization setup\n",
    "input_dim = TOTAL_INPUT_DIM\n",
    "\n",
    "# Define hyperparameter combinations\n",
    "hyperparameter_space = {\n",
    "    'vae_small': {\n",
    "        'latent_dim': 32,\n",
    "        'hidden_dim': 128,\n",
    "        'learning_rate': 5e-3,\n",
    "        'epochs': 500\n",
    "    },\n",
    "    'vae_medium': {\n",
    "        'latent_dim': 64,\n",
    "        'hidden_dim': 256,\n",
    "        'learning_rate': 1e-3,\n",
    "        'epochs': 750\n",
    "    },\n",
    "    'vae_large': {\n",
    "        'latent_dim': 128,\n",
    "        'hidden_dim': 512,\n",
    "        'learning_rate': 5e-4,\n",
    "        'epochs': 1000\n",
    "    }\n",
    "}\n",
    "\n",
    "num_epochs = 500\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be82a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    bce_loss_fn = nn.BCELoss(reduction='sum')\n",
    "    BCE = bce_loss_fn(recon_x, x)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c341e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: vae_small with params: {'latent_dim': 32, 'hidden_dim': 128, 'learning_rate': 0.005}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m     loss.backward()\n\u001b[32m     24\u001b[39m     total_loss += loss.item()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m avg_loss = total_loss / \u001b[38;5;28mlen\u001b[39m(data_tensor)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (epoch + \u001b[32m1\u001b[39m) % \u001b[32m50\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/music-gen-interpretability/lib/python3.12/site-packages/torch/optim/optimizer.py:470\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28mself\u001b[39m = cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    469\u001b[39m profile_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.step\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# call optimizer step pre hooks\u001b[39;49;00m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_global_optimizer_pre_hooks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step_pre_hooks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/music-gen-interpretability/lib/python3.12/site-packages/torch/autograd/profiler.py:788\u001b[39m, in \u001b[36mrecord_function.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting():\n\u001b[32m    787\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch._C.DisableTorchFunctionSubclass():\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_record_function_exit\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    790\u001b[39m     torch.ops.profiler._record_function_exit(record)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/music-gen-interpretability/lib/python3.12/site-packages/torch/_ops.py:995\u001b[39m, in \u001b[36mTorchBindOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    993\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._register_as_effectful_op_temporarily():\n\u001b[32m    994\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dispatch_in_python(args, kwargs, \u001b[38;5;28mself\u001b[39m._fallthrough_keys())\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for model_name, params in hyperparameter_space.items():\n",
    "    print(f\"Training model: {model_name} with params: {params}\")\n",
    "    \n",
    "    latent_dim = params['latent_dim']\n",
    "    hidden_dim = params['hidden_dim']\n",
    "    learning_rate = params['learning_rate']\n",
    "    num_epochs = params['epochs']\n",
    "    \n",
    "    model = MultiLabelVAE(input_dim, latent_dim, hidden_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    data_tensor = torch.tensor(data).to(device)\n",
    "    dataset = torch.utils.data.TensorDataset(data_tensor)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            inputs = batch[0]\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(inputs)\n",
    "            loss = vae_loss(recon_batch, inputs, mu, logvar)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(data_tensor)\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), f\"../models/{model_name}_vae.pth\")\n",
    "    print(f\"Model {model_name} saved.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38685f51",
   "metadata": {},
   "source": [
    "## Generate tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c5e71d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "      <th>genre_tags</th>\n",
       "      <th>mood_tags</th>\n",
       "      <th>instrument_tags</th>\n",
       "      <th>aspect_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>track_0007391</td>\n",
       "      <td>['genre---electronic', 'genre---pop', 'instrum...</td>\n",
       "      <td>[electronic, pop]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[bass, drums, guitar, keyboard]</td>\n",
       "      <td>[drums, bass, guitar, electronic, emotional, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track_0015161</td>\n",
       "      <td>['genre---instrumentalpop', 'genre---pop', 'ge...</td>\n",
       "      <td>[pop, rock]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[bass, drums]</td>\n",
       "      <td>[drums, bass, rock, emotional, pop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>track_0015166</td>\n",
       "      <td>['genre---dance', 'genre---electronic', 'genre...</td>\n",
       "      <td>[dance, electronic, pop, techno]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[bass]</td>\n",
       "      <td>[bass, electronic, dance, techno, emotional, pop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>track_0015167</td>\n",
       "      <td>['genre---chillout', 'genre---easylistening', ...</td>\n",
       "      <td>[electronic, pop]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[bass, violin]</td>\n",
       "      <td>[bass, electronic, emotional, pop, violin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>track_0015169</td>\n",
       "      <td>['genre---electronic', 'genre---instrumentalpo...</td>\n",
       "      <td>[electronic, pop]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[bass, drums]</td>\n",
       "      <td>[drums, bass, electronic, emotional, pop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>track_1420702</td>\n",
       "      <td>['genre---dance', 'genre---easylistening', 'ge...</td>\n",
       "      <td>[dance]</td>\n",
       "      <td>[funk, happy]</td>\n",
       "      <td>[bass, drums, keyboard]</td>\n",
       "      <td>[drums, bass, dance, funk, keyboard, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>track_1420704</td>\n",
       "      <td>['genre---dance', 'genre---easylistening', 'in...</td>\n",
       "      <td>[dance]</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>[bass, drums, keyboard]</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>track_1420705</td>\n",
       "      <td>['genre---dance', 'genre---easylistening', 'in...</td>\n",
       "      <td>[dance]</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>[bass, drums, keyboard]</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>track_1420706</td>\n",
       "      <td>['genre---dance', 'genre---easylistening', 'in...</td>\n",
       "      <td>[dance]</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>[bass, drums, keyboard]</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>track_1420707</td>\n",
       "      <td>['genre---chillout', 'genre---dance', 'genre--...</td>\n",
       "      <td>[dance, house]</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>[bass, drums, keyboard]</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy, house]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2041 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               tags  \\\n",
       "0     track_0007391  ['genre---electronic', 'genre---pop', 'instrum...   \n",
       "1     track_0015161  ['genre---instrumentalpop', 'genre---pop', 'ge...   \n",
       "2     track_0015166  ['genre---dance', 'genre---electronic', 'genre...   \n",
       "3     track_0015167  ['genre---chillout', 'genre---easylistening', ...   \n",
       "4     track_0015169  ['genre---electronic', 'genre---instrumentalpo...   \n",
       "...             ...                                                ...   \n",
       "2036  track_1420702  ['genre---dance', 'genre---easylistening', 'ge...   \n",
       "2037  track_1420704  ['genre---dance', 'genre---easylistening', 'in...   \n",
       "2038  track_1420705  ['genre---dance', 'genre---easylistening', 'in...   \n",
       "2039  track_1420706  ['genre---dance', 'genre---easylistening', 'in...   \n",
       "2040  track_1420707  ['genre---chillout', 'genre---dance', 'genre--...   \n",
       "\n",
       "                            genre_tags      mood_tags  \\\n",
       "0                    [electronic, pop]    [emotional]   \n",
       "1                          [pop, rock]    [emotional]   \n",
       "2     [dance, electronic, pop, techno]    [emotional]   \n",
       "3                    [electronic, pop]    [emotional]   \n",
       "4                    [electronic, pop]    [emotional]   \n",
       "...                                ...            ...   \n",
       "2036                           [dance]  [funk, happy]   \n",
       "2037                           [dance]        [happy]   \n",
       "2038                           [dance]        [happy]   \n",
       "2039                           [dance]        [happy]   \n",
       "2040                    [dance, house]        [happy]   \n",
       "\n",
       "                      instrument_tags  \\\n",
       "0     [bass, drums, guitar, keyboard]   \n",
       "1                       [bass, drums]   \n",
       "2                              [bass]   \n",
       "3                      [bass, violin]   \n",
       "4                       [bass, drums]   \n",
       "...                               ...   \n",
       "2036          [bass, drums, keyboard]   \n",
       "2037          [bass, drums, keyboard]   \n",
       "2038          [bass, drums, keyboard]   \n",
       "2039          [bass, drums, keyboard]   \n",
       "2040          [bass, drums, keyboard]   \n",
       "\n",
       "                                            aspect_list  \n",
       "0     [drums, bass, guitar, electronic, emotional, p...  \n",
       "1                   [drums, bass, rock, emotional, pop]  \n",
       "2     [bass, electronic, dance, techno, emotional, pop]  \n",
       "3            [bass, electronic, emotional, pop, violin]  \n",
       "4             [drums, bass, electronic, emotional, pop]  \n",
       "...                                                 ...  \n",
       "2036        [drums, bass, dance, funk, keyboard, happy]  \n",
       "2037              [drums, bass, dance, keyboard, happy]  \n",
       "2038              [drums, bass, dance, keyboard, happy]  \n",
       "2039              [drums, bass, dance, keyboard, happy]  \n",
       "2040       [drums, bass, dance, keyboard, happy, house]  \n",
       "\n",
       "[2041 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/mtg_jamendo/autotagging_top50tags_processed_cleaned.csv\")\n",
    "df['aspect_list'] = df['aspect_list'].apply(ast.literal_eval)\n",
    "df['instrument_tags'] = df['instrument_tags'].apply(ast.literal_eval)\n",
    "df['genre_tags'] = df['genre_tags'].apply(ast.literal_eval)\n",
    "df['mood_tags'] = df['mood_tags'].apply(ast.literal_eval)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1cb4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelVAE(\n",
       "  (fc1): Linear(in_features=200, out_features=256, bias=True)\n",
       "  (fc2_mu): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc2_logvar): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=200, bias=True)\n",
       "  (input_dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "hidden_dim = 256\n",
    "\n",
    "model = MultiLabelVAE(input_dim, latent_dim, hidden_dim).to(device)\n",
    "model.load_state_dict(torch.load(\"../models/vae_medium.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"✓ Best model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8dfa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tags(model, seed_tags, requests, temperature=1.0):\n",
    "    \"\"\"\n",
    "    seeds: List of tags we ALREADY have (e.g. ['rock', 'guitar'])\n",
    "    requests: Dict of how many tags we want per category (e.g. {'instrument': 2, 'mood': 1})\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # 1. Build the Input Vector from Seeds\n",
    "    input_vec = torch.zeros(1, TOTAL_INPUT_DIM).to(device)\n",
    "    \n",
    "    \n",
    "    # Fill in the knowns\n",
    "    for tag in seed_tags:\n",
    "        if tag in tag_to_idx:\n",
    "            input_vec[0, tag_to_idx[tag]] = 1.0\n",
    "        else:\n",
    "            print(f\"Warning: Seed tag '{tag}' not in taxonomy.\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 2. Encode to get the Latent Vibe (z)\n",
    "        # Note: We don't use dropout here; we want the model to use all clues we gave it.\n",
    "        mu, logvar = model.encode(input_vec)\n",
    "        z = model.reparameterize(mu, logvar)\n",
    "        \n",
    "        # 3. Decode to get probabilities for EVERYTHING\n",
    "        # Output shape: [1, Total_Dim] (Values 0.0 to 1.0)\n",
    "        probs = model.decode(z, temperature=temperature)[0] \n",
    "        \n",
    "        # 4. Extract Top-K for requested categories\n",
    "        results = {}\n",
    "        \n",
    "        for category, count in requests.items():\n",
    "            if count <= 0:\n",
    "                results[f\"generated_{category}_tags\"] = []\n",
    "                continue\n",
    "\n",
    "            start, end = cat_ranges[category]\n",
    "            \n",
    "            # Slice the probabilities relevant to this category\n",
    "            cat_probs = probs[start:end]\n",
    "            \n",
    "            # Get Top K indices for this slice\n",
    "            # We ask for count + len(seeds) just in case the model predicts the seed tag again\n",
    "            top_k_vals, top_k_indices = torch.topk(cat_probs, k=count + 5)\n",
    "            \n",
    "            # Convert slice-indices back to global-indices, then to strings\n",
    "            found_tags = []\n",
    "            for i in range(len(top_k_indices)):\n",
    "                local_idx = top_k_indices[i].item()\n",
    "                global_idx = start + local_idx\n",
    "                tag_name = idx_to_tag[global_idx][1]\n",
    "                \n",
    "                # Don't return tags we already provided as seeds\n",
    "                if tag_name not in seed_tags:\n",
    "                    found_tags.append(tag_name)\n",
    "                \n",
    "                if len(found_tags) == count:\n",
    "                    break\n",
    "            \n",
    "            results[f\"generated_{category}_tags\"] = found_tags\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa2b7d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(idx: int, tags_per_category: dict[str, int], temperature=1.0):\n",
    "    row = df.iloc[idx]\n",
    "    seed_tags = []\n",
    "    for category in ['genre', 'instrument', 'mood']:\n",
    "        if len(row[f\"{category}_tags\"]) > 1:\n",
    "            seed_tags.append(np.random.choice(row[f\"{category}_tags\"]))\n",
    "            tags_per_category[category] = tags_per_category.get(category, 1) - 1\n",
    "        \n",
    "    generated_tags = generate_tags(model, seed_tags, tags_per_category)\n",
    "    _generated_tags = []\n",
    "    for gtags in generated_tags.values():\n",
    "        _generated_tags.extend(gtags)\n",
    "\n",
    "    res_entry = {\n",
    "        'id': row['id'],\n",
    "        'original_aspect_list': row['aspect_list'],\n",
    "        'aspect_list': seed_tags + _generated_tags,\n",
    "        **generated_tags\n",
    "    }\n",
    "    return pd.DataFrame([res_entry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cce4f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\n",
    "    \"tempo\",\n",
    "    \"genre\",\n",
    "    \"mood\",\n",
    "    \"instrument\"\n",
    "]\n",
    "N_CATEGORIES = len(CATEGORIES)\n",
    "N_SAMPLES_TO_GENERATE = len(df)\n",
    "\n",
    "# --- 1. SYNTHETIC DATA GENERATION (Replace with your actual data) ---\n",
    "# We simulate a dataset where tag counts are discrete and correlated.\n",
    "# Max counts are defined for simulation purposes.\n",
    "MAX_COUNTS = {\n",
    "    \"tempo\": 6,\n",
    "    \"genre\": 6, \n",
    "    \"mood\": 7, \n",
    "    \"instrument\": 6, \n",
    "}\n",
    "MEANS = {\n",
    "    \"tempo\": 1.18,\n",
    "    \"genre\": 1.29, \n",
    "    \"mood\": 1.52, \n",
    "    \"instrument\": 2.08,\n",
    "}\n",
    "VARIANCES = {\n",
    "    \"tempo\": 0.54,\n",
    "    \"genre\": 0.65,\n",
    "    \"mood\": 0.91,\n",
    "    \"instrument\": 1.14,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70e0d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_correlated_data(n_records):\n",
    "    \"\"\"\n",
    "    Creates synthetic discrete count data that serves as the 'real' dataset.\n",
    "    This step is highly important: it determines the statistics (R and ECDFs)\n",
    "    that the Copula will try to match.\n",
    "    \"\"\"\n",
    "    print(\"--- 1. Generating Synthetic Data ---\")\n",
    "\n",
    "    # Define the desired correlation matrix (e.g., high correlation between Genre and Instrument)\n",
    "    # This represents your calculated correlation matrix R.\n",
    "    correlation_matrix = np.array([\n",
    "        [1.0, 0.17, 0.081, -0.035],  # Tempo\n",
    "        [0.17, 1.0, 0.55, -0.045],  # Genre\n",
    "        [0.081, 0.55, 1.0, -0.05],  # Mood\n",
    "        [-0.035, -0.045, -0.077, 1.0]   # Instrument\n",
    "    ])\n",
    "\n",
    "    # Generate correlated continuous data (Multivariate Normal)\n",
    "    mean = np.zeros(N_CATEGORIES)\n",
    "    z_continuous = multivariate_normal.rvs(mean=mean, cov=correlation_matrix, size=n_records)\n",
    "\n",
    "    data = np.zeros((n_records, N_CATEGORIES), dtype=int)\n",
    "    \n",
    "    # Transform continuous data into discrete counts based on desired marginals\n",
    "    # (using inverse CDF of an arbitrary discrete distribution for simulation)\n",
    "    # This simulates your real-world data having specific tag count distributions\n",
    "    for i, cat in enumerate(CATEGORIES):\n",
    "        max_c = MAX_COUNTS[cat]\n",
    "        # Simulate log normal-like distribution for counts\n",
    "        mu = np.log(MEANS[cat]**2 / np.sqrt(MEANS[cat]**2 + VARIANCES[cat]))\n",
    "        sigma = np.sqrt(np.log(1 + VARIANCES[cat] / MEANS[cat]**2))\n",
    "        # Create discrete probability distribution\n",
    "        x = np.arange(1, max_c + 1)\n",
    "        p = (1 / (x * sigma * np.sqrt(2 * np.pi)))\n",
    "        p *= np.exp(- (np.log(x) - mu)**2 / (2 * sigma**2))\n",
    "        p /= p.sum()  # Normalize to sum to 1\n",
    "        \n",
    "        # Convert continuous z (uniform quantile) to discrete count (inverse CDF)\n",
    "        uniform_quantiles = norm.cdf(z_continuous[:, i])\n",
    "        \n",
    "        # Quantile mapping for a simple discrete distribution\n",
    "        counts = np.digitize(uniform_quantiles, np.cumsum(p[:-1])) + 1\n",
    "        data[:, i] = np.clip(counts, 1, max_c)\n",
    "\n",
    "    print(f\"Synthetic Data Shape: {data.shape}\")\n",
    "    print(f\"Calculated Correlation of Synthetic Data:\\n{np.corrcoef(data.T).round(2)}\")\n",
    "    return data, correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda91803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Generating Synthetic Data ---\n",
      "Synthetic Data Shape: (2041, 4)\n",
      "Calculated Correlation of Synthetic Data:\n",
      "[[ 1.    0.09  0.07 -0.04]\n",
      " [ 0.09  1.    0.41 -0.04]\n",
      " [ 0.07  0.41  1.   -0.06]\n",
      " [-0.04 -0.04 -0.06  1.  ]]\n",
      "[[1 1 1 2]\n",
      " [1 2 1 2]\n",
      " [2 1 2 1]\n",
      " ...\n",
      " [1 1 2 3]\n",
      " [1 1 2 3]\n",
      " [1 1 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/miniconda3/envs/music-gen-interpretability/lib/python3.12/site-packages/scipy/stats/_multivariate.py:777: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  out = random_state.multivariate_normal(mean, cov, size)\n"
     ]
    }
   ],
   "source": [
    "data, _ = generate_synthetic_correlated_data(N_SAMPLES_TO_GENERATE)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bbb7173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_aspect_list</th>\n",
       "      <th>aspect_list</th>\n",
       "      <th>generated_tempo_tags</th>\n",
       "      <th>generated_genre_tags</th>\n",
       "      <th>generated_mood_tags</th>\n",
       "      <th>generated_instrument_tags</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>track_0007391</td>\n",
       "      <td>[drums, bass, guitar, electronic, emotional, p...</td>\n",
       "      <td>[pop, guitar, slow tempo, soothing, acoustic g...</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[soothing]</td>\n",
       "      <td>[acoustic guitar]</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track_0015161</td>\n",
       "      <td>[drums, bass, rock, emotional, pop]</td>\n",
       "      <td>[rock, drums, medium tempo, electronic music, ...</td>\n",
       "      <td>[medium tempo]</td>\n",
       "      <td>[electronic music]</td>\n",
       "      <td>[energetic]</td>\n",
       "      <td>[male singer]</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>track_0015166</td>\n",
       "      <td>[bass, electronic, dance, techno, emotional, pop]</td>\n",
       "      <td>[techno, fast tempo, uptempo, intense, suspens...</td>\n",
       "      <td>[fast tempo, uptempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[intense, suspenseful]</td>\n",
       "      <td>[clapping]</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>track_0015167</td>\n",
       "      <td>[bass, electronic, emotional, pop, violin]</td>\n",
       "      <td>[electronic, bass, uptempo, fast tempo, energe...</td>\n",
       "      <td>[uptempo, fast tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[energetic]</td>\n",
       "      <td>[digital drums, percussion, male voice, electr...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>track_0015169</td>\n",
       "      <td>[drums, bass, electronic, emotional, pop]</td>\n",
       "      <td>[pop, bass, medium tempo, fast tempo, eerie, i...</td>\n",
       "      <td>[medium tempo, fast tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[eerie, intense, mysterious]</td>\n",
       "      <td>[e-guitar]</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>track_1420702</td>\n",
       "      <td>[drums, bass, dance, funk, keyboard, happy]</td>\n",
       "      <td>[bass, funk, slow tempo, folk song, male voice]</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[folk song]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[male voice]</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>track_1420704</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[keyboard, slow tempo, movie soundtrack, emoti...</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[movie soundtrack]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[acoustic guitar]</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>track_1420705</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[keyboard, fast tempo, folk song, playful, joy...</td>\n",
       "      <td>[fast tempo]</td>\n",
       "      <td>[folk song]</td>\n",
       "      <td>[playful, joyful]</td>\n",
       "      <td>[male voice, percussion]</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>track_1420706</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[keyboard, slow tempo, classical music, soothi...</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[classical music]</td>\n",
       "      <td>[soothing, mellow]</td>\n",
       "      <td>[cello, acoustic guitar]</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>track_1420707</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy, house]</td>\n",
       "      <td>[house, drums, moderate tempo, happy mood]</td>\n",
       "      <td>[moderate tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[happy mood]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10205 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                               original_aspect_list  \\\n",
       "0      track_0007391  [drums, bass, guitar, electronic, emotional, p...   \n",
       "1      track_0015161                [drums, bass, rock, emotional, pop]   \n",
       "2      track_0015166  [bass, electronic, dance, techno, emotional, pop]   \n",
       "3      track_0015167         [bass, electronic, emotional, pop, violin]   \n",
       "4      track_0015169          [drums, bass, electronic, emotional, pop]   \n",
       "...              ...                                                ...   \n",
       "10200  track_1420702        [drums, bass, dance, funk, keyboard, happy]   \n",
       "10201  track_1420704              [drums, bass, dance, keyboard, happy]   \n",
       "10202  track_1420705              [drums, bass, dance, keyboard, happy]   \n",
       "10203  track_1420706              [drums, bass, dance, keyboard, happy]   \n",
       "10204  track_1420707       [drums, bass, dance, keyboard, happy, house]   \n",
       "\n",
       "                                             aspect_list  \\\n",
       "0      [pop, guitar, slow tempo, soothing, acoustic g...   \n",
       "1      [rock, drums, medium tempo, electronic music, ...   \n",
       "2      [techno, fast tempo, uptempo, intense, suspens...   \n",
       "3      [electronic, bass, uptempo, fast tempo, energe...   \n",
       "4      [pop, bass, medium tempo, fast tempo, eerie, i...   \n",
       "...                                                  ...   \n",
       "10200    [bass, funk, slow tempo, folk song, male voice]   \n",
       "10201  [keyboard, slow tempo, movie soundtrack, emoti...   \n",
       "10202  [keyboard, fast tempo, folk song, playful, joy...   \n",
       "10203  [keyboard, slow tempo, classical music, soothi...   \n",
       "10204         [house, drums, moderate tempo, happy mood]   \n",
       "\n",
       "             generated_tempo_tags generated_genre_tags  \\\n",
       "0                    [slow tempo]                   []   \n",
       "1                  [medium tempo]   [electronic music]   \n",
       "2           [fast tempo, uptempo]                   []   \n",
       "3           [uptempo, fast tempo]                   []   \n",
       "4      [medium tempo, fast tempo]                   []   \n",
       "...                           ...                  ...   \n",
       "10200                [slow tempo]          [folk song]   \n",
       "10201                [slow tempo]   [movie soundtrack]   \n",
       "10202                [fast tempo]          [folk song]   \n",
       "10203                [slow tempo]    [classical music]   \n",
       "10204            [moderate tempo]                   []   \n",
       "\n",
       "                generated_mood_tags  \\\n",
       "0                        [soothing]   \n",
       "1                       [energetic]   \n",
       "2            [intense, suspenseful]   \n",
       "3                       [energetic]   \n",
       "4      [eerie, intense, mysterious]   \n",
       "...                             ...   \n",
       "10200                            []   \n",
       "10201                   [emotional]   \n",
       "10202             [playful, joyful]   \n",
       "10203            [soothing, mellow]   \n",
       "10204                  [happy mood]   \n",
       "\n",
       "                               generated_instrument_tags  temperature  \n",
       "0                                      [acoustic guitar]         0.80  \n",
       "1                                          [male singer]         0.80  \n",
       "2                                             [clapping]         0.80  \n",
       "3      [digital drums, percussion, male voice, electr...         0.80  \n",
       "4                                             [e-guitar]         0.80  \n",
       "...                                                  ...          ...  \n",
       "10200                                       [male voice]         1.75  \n",
       "10201                                  [acoustic guitar]         1.75  \n",
       "10202                           [male voice, percussion]         1.75  \n",
       "10203                           [cello, acoustic guitar]         1.75  \n",
       "10204                                                 []         1.75  \n",
       "\n",
       "[10205 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatures = [0.8, 1.0, 1.25, 1.5, 1.75]\n",
    "\n",
    "res_df = pd.DataFrame()\n",
    "\n",
    "for temp in tqdm(temperatures):\n",
    "    for idx in tqdm(range(N_SAMPLES_TO_GENERATE), leave=False):\n",
    "        num_tags_for_category = {\n",
    "            \"tempo\": data[idx, 0],\n",
    "            \"genre\": data[idx, 1],\n",
    "            \"mood\": data[idx, 2],\n",
    "            \"instrument\": data[idx, 3],\n",
    "        }\n",
    "        temp_df = generate_df(idx, tags_per_category=num_tags_for_category, temperature=temp)\n",
    "        temp_df['temperature'] = temp\n",
    "        res_df = pd.concat([res_df, temp_df], ignore_index=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27f88e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_aspect_list</th>\n",
       "      <th>aspect_list</th>\n",
       "      <th>generated_tempo_tags</th>\n",
       "      <th>generated_genre_tags</th>\n",
       "      <th>generated_mood_tags</th>\n",
       "      <th>generated_instrument_tags</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>track_0007391</td>\n",
       "      <td>[drums, bass, guitar, electronic, emotional, p...</td>\n",
       "      <td>[acoustic guitar, guitar, pop, slow tempo, soo...</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[soothing]</td>\n",
       "      <td>[acoustic guitar]</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track_0015161</td>\n",
       "      <td>[drums, bass, rock, emotional, pop]</td>\n",
       "      <td>[drums, electronic music, energetic, male sing...</td>\n",
       "      <td>[medium tempo]</td>\n",
       "      <td>[electronic music]</td>\n",
       "      <td>[energetic]</td>\n",
       "      <td>[male singer]</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>track_0015166</td>\n",
       "      <td>[bass, electronic, dance, techno, emotional, pop]</td>\n",
       "      <td>[clapping, fast tempo, intense, suspenseful, t...</td>\n",
       "      <td>[fast tempo, uptempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[intense, suspenseful]</td>\n",
       "      <td>[clapping]</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>track_0015167</td>\n",
       "      <td>[bass, electronic, emotional, pop, violin]</td>\n",
       "      <td>[bass, digital drums, electronic, electronic d...</td>\n",
       "      <td>[uptempo, fast tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[energetic]</td>\n",
       "      <td>[digital drums, percussion, male voice, electr...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>track_0015169</td>\n",
       "      <td>[drums, bass, electronic, emotional, pop]</td>\n",
       "      <td>[bass, e-guitar, eerie, fast tempo, intense, m...</td>\n",
       "      <td>[medium tempo, fast tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[eerie, intense, mysterious]</td>\n",
       "      <td>[e-guitar]</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>track_1420702</td>\n",
       "      <td>[drums, bass, dance, funk, keyboard, happy]</td>\n",
       "      <td>[bass, folk song, funk, male voice, slow tempo]</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[folk song]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[male voice]</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>track_1420704</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[acoustic guitar, emotional, keyboard, movie s...</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[movie soundtrack]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[acoustic guitar]</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>track_1420705</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[fast tempo, folk song, joyful, keyboard, male...</td>\n",
       "      <td>[fast tempo]</td>\n",
       "      <td>[folk song]</td>\n",
       "      <td>[playful, joyful]</td>\n",
       "      <td>[male voice, percussion]</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9568</th>\n",
       "      <td>track_1420706</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[acoustic guitar, cello, classical music, keyb...</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[classical music]</td>\n",
       "      <td>[soothing, mellow]</td>\n",
       "      <td>[cello, acoustic guitar]</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9569</th>\n",
       "      <td>track_1420707</td>\n",
       "      <td>[drums, bass, dance, keyboard, happy, house]</td>\n",
       "      <td>[drums, happy mood, house, moderate tempo]</td>\n",
       "      <td>[moderate tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[happy mood]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                               original_aspect_list  \\\n",
       "0     track_0007391  [drums, bass, guitar, electronic, emotional, p...   \n",
       "1     track_0015161                [drums, bass, rock, emotional, pop]   \n",
       "2     track_0015166  [bass, electronic, dance, techno, emotional, pop]   \n",
       "3     track_0015167         [bass, electronic, emotional, pop, violin]   \n",
       "4     track_0015169          [drums, bass, electronic, emotional, pop]   \n",
       "...             ...                                                ...   \n",
       "9565  track_1420702        [drums, bass, dance, funk, keyboard, happy]   \n",
       "9566  track_1420704              [drums, bass, dance, keyboard, happy]   \n",
       "9567  track_1420705              [drums, bass, dance, keyboard, happy]   \n",
       "9568  track_1420706              [drums, bass, dance, keyboard, happy]   \n",
       "9569  track_1420707       [drums, bass, dance, keyboard, happy, house]   \n",
       "\n",
       "                                            aspect_list  \\\n",
       "0     [acoustic guitar, guitar, pop, slow tempo, soo...   \n",
       "1     [drums, electronic music, energetic, male sing...   \n",
       "2     [clapping, fast tempo, intense, suspenseful, t...   \n",
       "3     [bass, digital drums, electronic, electronic d...   \n",
       "4     [bass, e-guitar, eerie, fast tempo, intense, m...   \n",
       "...                                                 ...   \n",
       "9565    [bass, folk song, funk, male voice, slow tempo]   \n",
       "9566  [acoustic guitar, emotional, keyboard, movie s...   \n",
       "9567  [fast tempo, folk song, joyful, keyboard, male...   \n",
       "9568  [acoustic guitar, cello, classical music, keyb...   \n",
       "9569         [drums, happy mood, house, moderate tempo]   \n",
       "\n",
       "            generated_tempo_tags generated_genre_tags  \\\n",
       "0                   [slow tempo]                   []   \n",
       "1                 [medium tempo]   [electronic music]   \n",
       "2          [fast tempo, uptempo]                   []   \n",
       "3          [uptempo, fast tempo]                   []   \n",
       "4     [medium tempo, fast tempo]                   []   \n",
       "...                          ...                  ...   \n",
       "9565                [slow tempo]          [folk song]   \n",
       "9566                [slow tempo]   [movie soundtrack]   \n",
       "9567                [fast tempo]          [folk song]   \n",
       "9568                [slow tempo]    [classical music]   \n",
       "9569            [moderate tempo]                   []   \n",
       "\n",
       "               generated_mood_tags  \\\n",
       "0                       [soothing]   \n",
       "1                      [energetic]   \n",
       "2           [intense, suspenseful]   \n",
       "3                      [energetic]   \n",
       "4     [eerie, intense, mysterious]   \n",
       "...                            ...   \n",
       "9565                            []   \n",
       "9566                   [emotional]   \n",
       "9567             [playful, joyful]   \n",
       "9568            [soothing, mellow]   \n",
       "9569                  [happy mood]   \n",
       "\n",
       "                              generated_instrument_tags  temperature  \n",
       "0                                     [acoustic guitar]         0.80  \n",
       "1                                         [male singer]         0.80  \n",
       "2                                            [clapping]         0.80  \n",
       "3     [digital drums, percussion, male voice, electr...         0.80  \n",
       "4                                            [e-guitar]         0.80  \n",
       "...                                                 ...          ...  \n",
       "9565                                       [male voice]         1.75  \n",
       "9566                                  [acoustic guitar]         1.75  \n",
       "9567                           [male voice, percussion]         1.75  \n",
       "9568                           [cello, acoustic guitar]         1.75  \n",
       "9569                                                 []         1.75  \n",
       "\n",
       "[9570 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort aspect list column and deduplicate tag combinations\n",
    "res_df['aspect_list'] = res_df['aspect_list'].apply(lambda x: sorted(list(set(x))))\n",
    "res_df = res_df.drop_duplicates(subset=['aspect_list']).reset_index(drop=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "835e6471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_aspect_list</th>\n",
       "      <th>aspect_list</th>\n",
       "      <th>generated_tempo_tags</th>\n",
       "      <th>generated_genre_tags</th>\n",
       "      <th>generated_mood_tags</th>\n",
       "      <th>generated_instrument_tags</th>\n",
       "      <th>temperature</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[drums, bass, guitar, electronic, emotional, p...</td>\n",
       "      <td>[acoustic guitar, guitar, pop, slow tempo, soo...</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[soothing]</td>\n",
       "      <td>[acoustic guitar]</td>\n",
       "      <td>0.80</td>\n",
       "      <td>fcbb8aa0b93ef7b6da549497a1e4676f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[drums, bass, rock, emotional, pop]</td>\n",
       "      <td>[drums, electronic music, energetic, male sing...</td>\n",
       "      <td>[medium tempo]</td>\n",
       "      <td>[electronic music]</td>\n",
       "      <td>[energetic]</td>\n",
       "      <td>[male singer]</td>\n",
       "      <td>0.80</td>\n",
       "      <td>831702271c06dba496b65c120cbe2fbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bass, electronic, dance, techno, emotional, pop]</td>\n",
       "      <td>[clapping, fast tempo, intense, suspenseful, t...</td>\n",
       "      <td>[fast tempo, uptempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[intense, suspenseful]</td>\n",
       "      <td>[clapping]</td>\n",
       "      <td>0.80</td>\n",
       "      <td>42b34a3f75ac2b295df782e4bf93b9a8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[bass, electronic, emotional, pop, violin]</td>\n",
       "      <td>[bass, digital drums, electronic, electronic d...</td>\n",
       "      <td>[uptempo, fast tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[energetic]</td>\n",
       "      <td>[digital drums, percussion, male voice, electr...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>e465878054dcfdb69c60b0f460e05c07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[drums, bass, electronic, emotional, pop]</td>\n",
       "      <td>[bass, e-guitar, eerie, fast tempo, intense, m...</td>\n",
       "      <td>[medium tempo, fast tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[eerie, intense, mysterious]</td>\n",
       "      <td>[e-guitar]</td>\n",
       "      <td>0.80</td>\n",
       "      <td>dc206d3ba40cf46b9b34846ced92dab0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>[drums, bass, dance, funk, keyboard, happy]</td>\n",
       "      <td>[bass, folk song, funk, male voice, slow tempo]</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[folk song]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[male voice]</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2e4184f227dd05c3046300cbcd925dbb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[acoustic guitar, emotional, keyboard, movie s...</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[movie soundtrack]</td>\n",
       "      <td>[emotional]</td>\n",
       "      <td>[acoustic guitar]</td>\n",
       "      <td>1.75</td>\n",
       "      <td>b6b01cd5e879ce77a8819ed543934536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[fast tempo, folk song, joyful, keyboard, male...</td>\n",
       "      <td>[fast tempo]</td>\n",
       "      <td>[folk song]</td>\n",
       "      <td>[playful, joyful]</td>\n",
       "      <td>[male voice, percussion]</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0e148b77cb0c370cb090efbffc18bdf2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9568</th>\n",
       "      <td>[drums, bass, dance, keyboard, happy]</td>\n",
       "      <td>[acoustic guitar, cello, classical music, keyb...</td>\n",
       "      <td>[slow tempo]</td>\n",
       "      <td>[classical music]</td>\n",
       "      <td>[soothing, mellow]</td>\n",
       "      <td>[cello, acoustic guitar]</td>\n",
       "      <td>1.75</td>\n",
       "      <td>72827f099904be672eb86f905e405b69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9569</th>\n",
       "      <td>[drums, bass, dance, keyboard, happy, house]</td>\n",
       "      <td>[drums, happy mood, house, moderate tempo]</td>\n",
       "      <td>[moderate tempo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[happy mood]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.75</td>\n",
       "      <td>86d9ec041a1da1443907c70e9d0aacf0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   original_aspect_list  \\\n",
       "0     [drums, bass, guitar, electronic, emotional, p...   \n",
       "1                   [drums, bass, rock, emotional, pop]   \n",
       "2     [bass, electronic, dance, techno, emotional, pop]   \n",
       "3            [bass, electronic, emotional, pop, violin]   \n",
       "4             [drums, bass, electronic, emotional, pop]   \n",
       "...                                                 ...   \n",
       "9565        [drums, bass, dance, funk, keyboard, happy]   \n",
       "9566              [drums, bass, dance, keyboard, happy]   \n",
       "9567              [drums, bass, dance, keyboard, happy]   \n",
       "9568              [drums, bass, dance, keyboard, happy]   \n",
       "9569       [drums, bass, dance, keyboard, happy, house]   \n",
       "\n",
       "                                            aspect_list  \\\n",
       "0     [acoustic guitar, guitar, pop, slow tempo, soo...   \n",
       "1     [drums, electronic music, energetic, male sing...   \n",
       "2     [clapping, fast tempo, intense, suspenseful, t...   \n",
       "3     [bass, digital drums, electronic, electronic d...   \n",
       "4     [bass, e-guitar, eerie, fast tempo, intense, m...   \n",
       "...                                                 ...   \n",
       "9565    [bass, folk song, funk, male voice, slow tempo]   \n",
       "9566  [acoustic guitar, emotional, keyboard, movie s...   \n",
       "9567  [fast tempo, folk song, joyful, keyboard, male...   \n",
       "9568  [acoustic guitar, cello, classical music, keyb...   \n",
       "9569         [drums, happy mood, house, moderate tempo]   \n",
       "\n",
       "            generated_tempo_tags generated_genre_tags  \\\n",
       "0                   [slow tempo]                   []   \n",
       "1                 [medium tempo]   [electronic music]   \n",
       "2          [fast tempo, uptempo]                   []   \n",
       "3          [uptempo, fast tempo]                   []   \n",
       "4     [medium tempo, fast tempo]                   []   \n",
       "...                          ...                  ...   \n",
       "9565                [slow tempo]          [folk song]   \n",
       "9566                [slow tempo]   [movie soundtrack]   \n",
       "9567                [fast tempo]          [folk song]   \n",
       "9568                [slow tempo]    [classical music]   \n",
       "9569            [moderate tempo]                   []   \n",
       "\n",
       "               generated_mood_tags  \\\n",
       "0                       [soothing]   \n",
       "1                      [energetic]   \n",
       "2           [intense, suspenseful]   \n",
       "3                      [energetic]   \n",
       "4     [eerie, intense, mysterious]   \n",
       "...                            ...   \n",
       "9565                            []   \n",
       "9566                   [emotional]   \n",
       "9567             [playful, joyful]   \n",
       "9568            [soothing, mellow]   \n",
       "9569                  [happy mood]   \n",
       "\n",
       "                              generated_instrument_tags  temperature  \\\n",
       "0                                     [acoustic guitar]         0.80   \n",
       "1                                         [male singer]         0.80   \n",
       "2                                            [clapping]         0.80   \n",
       "3     [digital drums, percussion, male voice, electr...         0.80   \n",
       "4                                            [e-guitar]         0.80   \n",
       "...                                                 ...          ...   \n",
       "9565                                       [male voice]         1.75   \n",
       "9566                                  [acoustic guitar]         1.75   \n",
       "9567                           [male voice, percussion]         1.75   \n",
       "9568                           [cello, acoustic guitar]         1.75   \n",
       "9569                                                 []         1.75   \n",
       "\n",
       "                                    id  \n",
       "0     fcbb8aa0b93ef7b6da549497a1e4676f  \n",
       "1     831702271c06dba496b65c120cbe2fbc  \n",
       "2     42b34a3f75ac2b295df782e4bf93b9a8  \n",
       "3     e465878054dcfdb69c60b0f460e05c07  \n",
       "4     dc206d3ba40cf46b9b34846ced92dab0  \n",
       "...                                ...  \n",
       "9565  2e4184f227dd05c3046300cbcd925dbb  \n",
       "9566  b6b01cd5e879ce77a8819ed543934536  \n",
       "9567  0e148b77cb0c370cb090efbffc18bdf2  \n",
       "9568  72827f099904be672eb86f905e405b69  \n",
       "9569  86d9ec041a1da1443907c70e9d0aacf0  \n",
       "\n",
       "[9570 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add surrogate key based on track_id and temperature\n",
    "import hashlib\n",
    "def generate_surrogate_key(track_id: str, temperature: float) -> str:\n",
    "    key_str = f\"{track_id}_{temperature}\"\n",
    "    return hashlib.md5(key_str.encode()).hexdigest()\n",
    "\n",
    "res_df['surrogate_key'] = res_df.apply(lambda row: generate_surrogate_key(row['id'], row['temperature']), axis=1)\n",
    "res_df.drop(columns=['id'], inplace=True)\n",
    "res_df.rename(columns={'surrogate_key': 'id'}, inplace=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680d5ad",
   "metadata": {},
   "source": [
    "## Push to Hugginface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dce411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_valid = train_test_split(res_df, test_size=0.1, random_state=42)\n",
    "df_valid, df_test = train_test_split(df_valid, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ee617a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"../data/vae_mtg_tags\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_train.to_csv(output_dir / \"train.csv\", index=False)\n",
    "df_valid.to_csv(output_dir / \"validation.csv\", index=False)\n",
    "df_test.to_csv(output_dir / \"test.csv\", index=False)\n",
    "all_df = pd.concat([df_train, df_valid, df_test])\n",
    "all_df.to_csv(output_dir / \"all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "458a3829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0b5bbafa2741c2adebdae74afd4d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4652ebe7fda44c79cc88021fda5c700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a393875b9f4e819e5cb7f2aaf1cd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a570f8148c54482a456d39912f7d5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568454ffdb2144c09ea02611053083b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7defd47981254bc892c23916c2285ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff22e4bb4fb4d80b69407b1c2d729d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4546d6988fdb41ada268b467c1914e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d8ad7db4dc4eb99d7b92bd3e793e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261b7f4125544e1ba43a345d4e0ddc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df581c0d205411ba8d2d6e2b9ba372b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69af10d44564abf9b981623c5fdef96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d89f94d98c42a8bad59ea3f2095f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae6e0b9a5ec4a9fa8adb6f86623c47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3d4a73f6534ef48c4adaf795aa2659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0673a7f7e34602bcdc92cbe2f5ba0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/813 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/bsienkiewicz/mtg_vae_tags_dataset/commit/22330a0a073999aa0fe06540f535f1cb57af7032', commit_message='Upload dataset', commit_description='', oid='22330a0a073999aa0fe06540f535f1cb57af7032', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/bsienkiewicz/mtg_vae_tags_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='bsienkiewicz/mtg_vae_tags_dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": str(output_dir / \"train.csv\"),\n",
    "    \"validation\": str(output_dir / \"validation.csv\"),\n",
    "    \"test\": str(output_dir / \"test.csv\")\n",
    "}\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "dataset.push_to_hub(\"bsienkiewicz/mtg_vae_tags_dataset\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-gen-interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
