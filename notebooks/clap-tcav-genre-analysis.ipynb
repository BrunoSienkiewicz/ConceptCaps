{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f059dd75",
   "metadata": {},
   "source": [
    "# TCAV Analysis on CLAP Model for Genre Concepts\n",
    "## Using MusicCaps Dataset to Interpret Genre-Specific Concept Importance\n",
    "\n",
    "This notebook performs Testing with Concept Activation Vectors (TCAV) analysis on the pre-trained CLAP model to understand how the model's internal representations respond to different music genres (pop, rock, classical). We use the MusicCaps dataset with genre descriptions to create text-based concepts and analyze their influence across model layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535a4d8",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20483e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# Model and data loading\n",
    "from transformers import ClapModel, ClapProcessor, AutoTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from scipy import stats\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a22ef3",
   "metadata": {},
   "source": [
    "## 2. Load and Explore MusicCaps Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc435d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MusicCaps dataset with descriptions\n",
    "musiccaps_path = Path(\"../data/musiccaps_tags_to_description_dataset.csv\")\n",
    "df = pd.read_csv(musiccaps_path)\n",
    "\n",
    "print(f\"MusicCaps dataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ba92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter samples by genre\n",
    "genres_of_interest = ['pop', 'rock', 'classical']\n",
    "\n",
    "def extract_genre_from_tags(tags_str):\n",
    "    \"\"\"Extract genre from genre_tags column\"\"\"\n",
    "    if pd.isna(tags_str):\n",
    "        return None\n",
    "    tags = str(tags_str).lower().split(', ')\n",
    "    for tag in tags:\n",
    "        for genre in genres_of_interest:\n",
    "            if genre in tag.lower():\n",
    "                return genre\n",
    "    return None\n",
    "\n",
    "df['primary_genre'] = df['genre_tags'].apply(extract_genre_from_tags)\n",
    "\n",
    "# Create separate dataframes for each genre\n",
    "genre_dfs = {}\n",
    "for genre in genres_of_interest:\n",
    "    genre_dfs[genre] = df[df['primary_genre'] == genre].head(50)  # Limit to 50 samples per genre\n",
    "    print(f\"\\n{genre.upper()} samples: {len(genre_dfs[genre])}\")\n",
    "    print(f\"Sample descriptions:\")\n",
    "    for idx, desc in enumerate(genre_dfs[genre]['caption'].head(3)):\n",
    "        print(f\"  {idx+1}. {desc[:100]}...\")\n",
    "\n",
    "# Combine all samples\n",
    "all_genre_samples = pd.concat([genre_dfs[genre] for genre in genres_of_interest], ignore_index=True)\n",
    "print(f\"\\nTotal samples for analysis: {len(all_genre_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97366b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Genre distribution\n",
    "genre_counts = all_genre_samples['primary_genre'].value_counts()\n",
    "axes[0].bar(genre_counts.index, genre_counts.values, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[0].set_title('Distribution of Genres in Analysis Dataset')\n",
    "axes[0].set_ylabel('Number of Samples')\n",
    "axes[0].set_xlabel('Genre')\n",
    "\n",
    "# Caption length distribution\n",
    "all_genre_samples['caption_length'] = all_genre_samples['caption'].str.len()\n",
    "for genre in genres_of_interest:\n",
    "    genre_data = genre_dfs[genre]['caption'].str.len()\n",
    "    axes[1].hist(genre_data, alpha=0.5, label=genre, bins=20)\n",
    "axes[1].set_title('Distribution of Caption Lengths by Genre')\n",
    "axes[1].set_xlabel('Caption Length')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCaption length statistics:\")\n",
    "print(all_genre_samples.groupby('primary_genre')['caption_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c167809",
   "metadata": {},
   "source": [
    "## 3. Prepare Genre-Specific Text Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define genre concepts with descriptive keywords\n",
    "genre_concepts = {\n",
    "    'pop': [\n",
    "        'pop music with catchy melodies',\n",
    "        'upbeat pop song with pop production',\n",
    "        'pop genre with pop rhythms',\n",
    "        'commercial pop music',\n",
    "        'pop style music',\n",
    "        'contemporary pop',\n",
    "        'popular pop music',\n",
    "    ],\n",
    "    'rock': [\n",
    "        'rock music with electric guitars',\n",
    "        'rock genre with rock drums',\n",
    "        'heavy rock sound',\n",
    "        'rock and roll style',\n",
    "        'rock guitar riffs',\n",
    "        'loud rock song',\n",
    "        'rock music style',\n",
    "    ],\n",
    "    'classical': [\n",
    "        'classical music composition',\n",
    "        'classical orchestra arrangement',\n",
    "        'classical music with strings',\n",
    "        'classical symphony style',\n",
    "        'classical genre music',\n",
    "        'classical instrumental',\n",
    "        'classical orchestral piece',\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Genre Concepts Prepared:\")\n",
    "for genre, concepts in genre_concepts.items():\n",
    "    print(f\"\\n{genre.upper()}:\")\n",
    "    for i, concept in enumerate(concepts, 1):\n",
    "        print(f\"  {i}. {concept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f3fd53",
   "metadata": {},
   "source": [
    "## 4. Load Pre-trained CLAP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8caedef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLAP model and processor\n",
    "print(\"Loading CLAP model...\")\n",
    "model_name = \"laion/clap-htsat-unfused\"\n",
    "model = ClapModel.from_pretrained(model_name).to(device)\n",
    "processor = ClapProcessor.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d057b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hook to extract intermediate layer activations\n",
    "layer_activations = {}\n",
    "\n",
    "def get_activation_hook(name):\n",
    "    def hook(model, input, output):\n",
    "        layer_activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Select layers for analysis (using text encoder layers as TCAV concepts are text-based)\n",
    "selected_layers = [\n",
    "    'text_model.encoder.layers.0',\n",
    "    'text_model.encoder.layers.2',\n",
    "    'text_model.encoder.layers.4',\n",
    "    'text_model.encoder.layers.6',\n",
    "    'text_model.encoder.layers.8',\n",
    "    'text_model.encoder.layers.10',\n",
    "    'text_model.encoder.layers.11',  # Final layer\n",
    "]\n",
    "\n",
    "# Register hooks for selected layers\n",
    "handles = []\n",
    "for layer_name in selected_layers:\n",
    "    layer = dict(model.named_modules()).get(layer_name)\n",
    "    if layer is not None:\n",
    "        handle = layer.register_forward_hook(get_activation_hook(layer_name))\n",
    "        handles.append(handle)\n",
    "        print(f\"Hook registered for layer: {layer_name}\")\n",
    "\n",
    "print(f\"\\nTotal hooks registered: {len(handles)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c456785a",
   "metadata": {},
   "source": [
    "## 5. Extract Text Embeddings for Genre Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text embeddings for genre concepts\n",
    "genre_embeddings = {}\n",
    "concept_activations = {}  # Store activations at each layer\n",
    "\n",
    "print(\"Extracting text embeddings for genre concepts...\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for genre, concepts in genre_concepts.items():\n",
    "        print(f\"Processing {genre.upper()} concepts...\")\n",
    "        genre_embeddings[genre] = []\n",
    "        concept_activations[genre] = {layer: [] for layer in selected_layers}\n",
    "        \n",
    "        for concept in concepts:\n",
    "            # Tokenize and process text\n",
    "            inputs = processor(text=[concept], return_tensors=\"pt\", padding=True).to(device)\n",
    "            \n",
    "            # Clear previous activations\n",
    "            layer_activations.clear()\n",
    "            \n",
    "            # Forward pass to extract embeddings\n",
    "            outputs = model.get_text_features(**inputs)\n",
    "            \n",
    "            # Store embeddings\n",
    "            genre_embeddings[genre].append(outputs.cpu())\n",
    "            \n",
    "            # Store activations from each layer\n",
    "            for layer_name in selected_layers:\n",
    "                if layer_name in layer_activations:\n",
    "                    activation = layer_activations[layer_name]\n",
    "                    # Take the CLS token (first token) activations\n",
    "                    cls_activation = activation[:, 0, :]  # Shape: (batch_size, hidden_dim)\n",
    "                    concept_activations[genre][layer_name].append(cls_activation.cpu())\n",
    "        \n",
    "        # Average embeddings for each genre\n",
    "        genre_embeddings[genre] = torch.cat(genre_embeddings[genre], dim=0).mean(dim=0, keepdim=True)\n",
    "        \n",
    "        # Average activations for each layer and genre\n",
    "        for layer_name in selected_layers:\n",
    "            if concept_activations[genre][layer_name]:\n",
    "                concept_activations[genre][layer_name] = torch.cat(\n",
    "                    concept_activations[genre][layer_name], dim=0\n",
    "                ).mean(dim=0, keepdim=True)\n",
    "        \n",
    "        print(f\"  ✓ Extracted embeddings, shape: {genre_embeddings[genre].shape}\\n\")\n",
    "\n",
    "print(\"Text embeddings extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd6099",
   "metadata": {},
   "source": [
    "## 6. Extract Audio Activations from Sample Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract activations from MusicCaps descriptions for each genre\n",
    "sample_activations = {}  # {genre: {layer: activations}}\n",
    "\n",
    "print(\"Extracting activations from MusicCaps descriptions...\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for genre in genres_of_interest:\n",
    "        print(f\"Processing {genre.upper()} samples...\")\n",
    "        sample_activations[genre] = {layer: [] for layer in selected_layers}\n",
    "        \n",
    "        descriptions = genre_dfs[genre]['caption'].values\n",
    "        \n",
    "        for desc in tqdm(descriptions[:30], desc=f\"  {genre}\"):  # Limit to 30 samples per genre for efficiency\n",
    "            try:\n",
    "                # Tokenize and process text description\n",
    "                inputs = processor(text=[str(desc)], return_tensors=\"pt\", padding=True).to(device)\n",
    "                \n",
    "                # Clear previous activations\n",
    "                layer_activations.clear()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model.get_text_features(**inputs)\n",
    "                \n",
    "                # Store activations from each layer\n",
    "                for layer_name in selected_layers:\n",
    "                    if layer_name in layer_activations:\n",
    "                        activation = layer_activations[layer_name]\n",
    "                        # Take the CLS token activations\n",
    "                        cls_activation = activation[:, 0, :]  # Shape: (1, hidden_dim)\n",
    "                        sample_activations[genre][layer_name].append(cls_activation.cpu())\n",
    "            except Exception as e:\n",
    "                print(f\"    Warning: Failed to process sample: {str(e)[:50]}\")\n",
    "                continue\n",
    "        \n",
    "        # Convert to tensors and stack\n",
    "        for layer_name in selected_layers:\n",
    "            if sample_activations[genre][layer_name]:\n",
    "                sample_activations[genre][layer_name] = torch.cat(\n",
    "                    sample_activations[genre][layer_name], dim=0\n",
    "                )\n",
    "        \n",
    "        print(f\"  ✓ Processed {len(descriptions[:30])} samples\\n\")\n",
    "\n",
    "print(\"Sample activations extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66aa125",
   "metadata": {},
   "source": [
    "## 7. Compute TCAV Vectors for Genre Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCAV computation: Learn linear decision boundaries between genre concepts\n",
    "tcav_vectors = {}  # {genre: {layer: direction_vector}}\n",
    "tcav_accuracies = {}  # {genre: {layer: accuracy}}\n",
    "\n",
    "print(\"Computing TCAV vectors...\\n\")\n",
    "\n",
    "for genre in genres_of_interest:\n",
    "    print(f\"Computing TCAV for {genre.upper()}...\")\n",
    "    tcav_vectors[genre] = {}\n",
    "    tcav_accuracies[genre] = {}\n",
    "    \n",
    "    for layer_name in selected_layers:\n",
    "        # Prepare data for this genre vs. others\n",
    "        # Positive class: this genre (concept activations)\n",
    "        positive_samples = concept_activations[genre][layer_name].numpy()\n",
    "        \n",
    "        # Negative class: other genres (sampled from other genre descriptions)\n",
    "        negative_samples_list = []\n",
    "        for other_genre in genres_of_interest:\n",
    "            if other_genre != genre:\n",
    "                if layer_name in sample_activations[other_genre] and len(sample_activations[other_genre][layer_name]) > 0:\n",
    "                    negative_samples_list.append(sample_activations[other_genre][layer_name].numpy())\n",
    "        \n",
    "        if not negative_samples_list:\n",
    "            print(f\"  ⚠ Skipping {layer_name}: insufficient negative samples\")\n",
    "            continue\n",
    "        \n",
    "        negative_samples = np.vstack(negative_samples_list)\n",
    "        \n",
    "        # Create binary classification dataset\n",
    "        X = np.vstack([positive_samples, negative_samples])\n",
    "        y = np.hstack([np.ones(len(positive_samples)), np.zeros(len(negative_samples))])\n",
    "        \n",
    "        # Normalize features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Train linear classifier (TCAV)\n",
    "        clf = LogisticRegression(max_iter=1000, random_state=random_state)\n",
    "        clf.fit(X_scaled, y)\n",
    "        \n",
    "        # Store TCAV vector (direction of concept)\n",
    "        tcav_vectors[genre][layer_name] = torch.tensor(clf.coef_[0], dtype=torch.float32)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        y_pred = clf.predict(X_scaled)\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        tcav_accuracies[genre][layer_name] = accuracy\n",
    "    \n",
    "    print(f\"  ✓ TCAV vectors computed for {len(tcav_vectors[genre])} layers\\n\")\n",
    "\n",
    "print(\"TCAV vector computation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea024782",
   "metadata": {},
   "source": [
    "## 8. Calculate TCAV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb26592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TCAV scores: measure of how much the concept matters at each layer\n",
    "# TCAV score = how well the direction of the concept aligns with sample activations\n",
    "\n",
    "tcav_scores = {}  # {genre: {layer: score}}\n",
    "\n",
    "print(\"Computing TCAV scores...\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for genre in genres_of_interest:\n",
    "        print(f\"Computing scores for {genre.upper()}...\")\n",
    "        tcav_scores[genre] = {}\n",
    "        \n",
    "        for layer_name in selected_layers:\n",
    "            if layer_name not in tcav_vectors[genre]:\n",
    "                continue\n",
    "            \n",
    "            # Get TCAV vector (direction of concept)\n",
    "            tcav_direction = tcav_vectors[genre][layer_name].to(device)\n",
    "            \n",
    "            # Get sample activations for this genre\n",
    "            if layer_name not in sample_activations[genre] or len(sample_activations[genre][layer_name]) == 0:\n",
    "                tcav_scores[genre][layer_name] = 0.0\n",
    "                continue\n",
    "            \n",
    "            sample_acts = sample_activations[genre][layer_name].to(device)\n",
    "            \n",
    "            # Normalize both vectors\n",
    "            tcav_direction_norm = F.normalize(tcav_direction.unsqueeze(0), p=2, dim=1)[0]\n",
    "            sample_acts_norm = F.normalize(sample_acts, p=2, dim=1)\n",
    "            \n",
    "            # Compute cosine similarity (dot product after normalization)\n",
    "            # This measures how much samples align with the concept direction\n",
    "            cosine_sims = torch.matmul(sample_acts_norm, tcav_direction_norm)\n",
    "            \n",
    "            # TCAV score is the mean of positive activations (ReLU)\n",
    "            tcav_score = torch.relu(cosine_sims).mean().item()\n",
    "            tcav_scores[genre][layer_name] = tcav_score\n",
    "        \n",
    "        print(f\"  ✓ Scores computed\\n\")\n",
    "\n",
    "print(\"TCAV score computation complete!\")\n",
    "\n",
    "# Create summary dataframe\n",
    "tcav_df = pd.DataFrame(tcav_scores).T\n",
    "print(\"\\nTCAV Scores Summary:\")\n",
    "print(tcav_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d20d54",
   "metadata": {},
   "source": [
    "## 9. Visualize TCAV Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7935f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for visualization\n",
    "tcav_data_for_plot = []\n",
    "for genre in genres_of_interest:\n",
    "    for layer_name in selected_layers:\n",
    "        if layer_name in tcav_scores[genre]:\n",
    "            layer_idx = int(layer_name.split('.')[-1])\n",
    "            tcav_data_for_plot.append({\n",
    "                'genre': genre,\n",
    "                'layer': layer_idx,\n",
    "                'layer_name': layer_name,\n",
    "                'tcav_score': tcav_scores[genre][layer_name],\n",
    "                'accuracy': tcav_accuracies[genre].get(layer_name, 0.0)\n",
    "            })\n",
    "\n",
    "tcav_plot_df = pd.DataFrame(tcav_data_for_plot)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. TCAV Scores Heatmap\n",
    "heatmap_data = tcav_plot_df.pivot_table(\n",
    "    values='tcav_score', \n",
    "    index='genre', \n",
    "    columns='layer'\n",
    ")\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='RdYlGn', ax=axes[0, 0], cbar_kws={'label': 'TCAV Score'})\n",
    "axes[0, 0].set_title('TCAV Scores Across Model Layers', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Layer Index')\n",
    "axes[0, 0].set_ylabel('Genre')\n",
    "\n",
    "# 2. TCAV Scores Line Plot\n",
    "for genre in genres_of_interest:\n",
    "    genre_data = tcav_plot_df[tcav_plot_df['genre'] == genre].sort_values('layer')\n",
    "    axes[0, 1].plot(genre_data['layer'], genre_data['tcav_score'], marker='o', label=genre, linewidth=2)\n",
    "\n",
    "axes[0, 1].set_xlabel('Layer Index')\n",
    "axes[0, 1].set_ylabel('TCAV Score')\n",
    "axes[0, 1].set_title('Genre Sensitivity Across Layers', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Classifier Accuracy\n",
    "accuracy_data = tcav_plot_df.pivot_table(\n",
    "    values='accuracy', \n",
    "    index='genre', \n",
    "    columns='layer'\n",
    ")\n",
    "sns.heatmap(accuracy_data, annot=True, fmt='.3f', cmap='Blues', ax=axes[1, 0], cbar_kws={'label': 'Accuracy'})\n",
    "axes[1, 0].set_title('Binary Classification Accuracy by Genre and Layer', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Layer Index')\n",
    "axes[1, 0].set_ylabel('Genre')\n",
    "\n",
    "# 4. Average TCAV Score by Genre\n",
    "avg_scores = tcav_plot_df.groupby('genre')['tcav_score'].mean().sort_values(ascending=False)\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "axes[1, 1].bar(avg_scores.index, avg_scores.values, color=colors[:len(avg_scores)])\n",
    "axes[1, 1].set_title('Average TCAV Score by Genre', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Average TCAV Score')\n",
    "axes[1, 1].set_xlabel('Genre')\n",
    "\n",
    "for i, v in enumerate(avg_scores.values):\n",
    "    axes[1, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TCAV ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAverage TCAV Scores by Genre:\")\n",
    "print(avg_scores.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfc728",
   "metadata": {},
   "source": [
    "## 10. Layer-wise Analysis and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb33c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which layers are most important for each genre\n",
    "print(\"=\"*80)\n",
    "print(\"LAYER-WISE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "layer_importance = {}\n",
    "\n",
    "for genre in genres_of_interest:\n",
    "    print(f\"\\n{genre.upper()} GENRE:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    genre_scores = [(layer, score) for layer, score in tcav_scores[genre].items()]\n",
    "    genre_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Top layers by TCAV score:\")\n",
    "    for i, (layer, score) in enumerate(genre_scores[:3], 1):\n",
    "        layer_idx = int(layer.split('.')[-1])\n",
    "        accuracy = tcav_accuracies[genre].get(layer, 0.0)\n",
    "        print(f\"  {i}. Layer {layer_idx}: TCAV Score = {score:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "    # Store for later analysis\n",
    "    if genre_scores:\n",
    "        top_layer = genre_scores[0][0]\n",
    "        layer_importance[genre] = (top_layer, genre_scores[0][1])\n",
    "\n",
    "# Identify critical layers for each genre\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CRITICAL LAYERS PER GENRE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for genre, (layer, score) in layer_importance.items():\n",
    "    layer_idx = int(layer.split('.')[-1])\n",
    "    print(f\"{genre.upper():10} -> Layer {layer_idx} (TCAV Score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b253d6",
   "metadata": {},
   "source": [
    "## 11. Concept Vector Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the similarity between genre concept vectors\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENRE CONCEPT VECTOR SIMILARITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select a middle layer for analysis\n",
    "analysis_layer = selected_layers[len(selected_layers) // 2]\n",
    "layer_idx = int(analysis_layer.split('.')[-1])\n",
    "\n",
    "print(f\"\\nAnalyzing concept vectors at Layer {layer_idx}:\\n\")\n",
    "\n",
    "# Compute pairwise similarities between genre TCAV vectors\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "similarity_matrix = np.zeros((len(genres_of_interest), len(genres_of_interest)))\n",
    "\n",
    "for i, genre1 in enumerate(genres_of_interest):\n",
    "    for j, genre2 in enumerate(genres_of_interest):\n",
    "        if analysis_layer in tcav_vectors[genre1] and analysis_layer in tcav_vectors[genre2]:\n",
    "            vec1 = tcav_vectors[genre1][analysis_layer].numpy()\n",
    "            vec2 = tcav_vectors[genre2][analysis_layer].numpy()\n",
    "            \n",
    "            # Normalize vectors\n",
    "            vec1_norm = vec1 / (np.linalg.norm(vec1) + 1e-8)\n",
    "            vec2_norm = vec2 / (np.linalg.norm(vec2) + 1e-8)\n",
    "            \n",
    "            # Compute cosine similarity\n",
    "            similarity = 1 - cosine(vec1_norm, vec2_norm)\n",
    "            similarity_matrix[i, j] = similarity\n",
    "\n",
    "# Visualize similarity matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "sns.heatmap(similarity_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            xticklabels=genres_of_interest, yticklabels=genres_of_interest,\n",
    "            ax=ax, cbar_kws={'label': 'Cosine Similarity'}, vmin=-1, vmax=1)\n",
    "ax.set_title(f'Genre TCAV Vector Similarity at Layer {layer_idx}', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Pairwise Similarity Matrix:\")\n",
    "for i, genre1 in enumerate(genres_of_interest):\n",
    "    for j, genre2 in enumerate(genres_of_interest):\n",
    "        print(f\"  {genre1} <-> {genre2}: {similarity_matrix[i, j]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5723f64b",
   "metadata": {},
   "source": [
    "## 12. Key Findings and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eabda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary report\n",
    "report = \"\"\"\n",
    "================================================================================\n",
    "                    TCAV ANALYSIS REPORT: CLAP MODEL GENRES\n",
    "================================================================================\n",
    "\n",
    "METHODOLOGY:\n",
    "-----------\n",
    "Testing with Concept Activation Vectors (TCAV) is used to interpret how neural \n",
    "networks respond to human-understandable concepts (genres). For each genre, we:\n",
    "\n",
    "1. Create text-based concept embeddings using genre-specific descriptions\n",
    "2. Extract intermediate layer activations from sample descriptions\n",
    "3. Train linear classifiers to learn the direction of each concept\n",
    "4. Compute TCAV scores measuring layer sensitivity to genre concepts\n",
    "\n",
    "RESULTS SUMMARY:\n",
    "----------------\n",
    "\"\"\"\n",
    "\n",
    "# Add genre-level statistics\n",
    "report += \"\\nGenre-Level Statistics:\\n\"\n",
    "for genre in genres_of_interest:\n",
    "    genre_scores = [tcav_scores[genre].get(layer, 0) for layer in selected_layers]\n",
    "    report += f\"\\n  {genre.upper()}:\\n\"\n",
    "    report += f\"    - Average TCAV Score: {np.mean(genre_scores):.4f}\\n\"\n",
    "    report += f\"    - Max TCAV Score: {np.max(genre_scores):.4f}\\n\"\n",
    "    report += f\"    - Min TCAV Score: {np.min(genre_scores):.4f}\\n\"\n",
    "\n",
    "# Add layer-level analysis\n",
    "report += \"\\n\\nLayer-Level Analysis:\\n\"\n",
    "report += \"-\" * 40 + \"\\n\"\n",
    "\n",
    "for layer_idx, layer_name in enumerate(selected_layers):\n",
    "    layer_num = int(layer_name.split('.')[-1])\n",
    "    report += f\"\\n  Layer {layer_num}:\\n\"\n",
    "    for genre in genres_of_interest:\n",
    "        score = tcav_scores[genre].get(layer_name, 0)\n",
    "        accuracy = tcav_accuracies[genre].get(layer_name, 0)\n",
    "        report += f\"    {genre:10} - TCAV: {score:.4f}, Accuracy: {accuracy:.4f}\\n\"\n",
    "\n",
    "# Add key insights\n",
    "report += \"\\n\\nKEY INSIGHTS:\\n\"\n",
    "report += \"=\" * 80 + \"\\n\"\n",
    "\n",
    "# Most discriminative layers\n",
    "report += \"\\n1. Most Discriminative Layers per Genre:\\n\"\n",
    "for genre, (layer, score) in layer_importance.items():\n",
    "    layer_idx = int(layer.split('.')[-1])\n",
    "    report += f\"   - {genre.upper():10} most responsive at Layer {layer_idx} (Score: {score:.4f})\\n\"\n",
    "\n",
    "# Genre distinctiveness\n",
    "report += \"\\n2. Genre Concept Distinctiveness:\\n\"\n",
    "report += \"   (Higher similarity indicates more overlapping representations)\\n\"\n",
    "for i, genre1 in enumerate(genres_of_interest):\n",
    "    for j, genre2 in enumerate(genres_of_interest):\n",
    "        if i < j:\n",
    "            sim = similarity_matrix[i, j]\n",
    "            distinctiveness = \"overlapping\" if sim > 0.5 else \"distinct\"\n",
    "            report += f\"   - {genre1.upper()} vs {genre2.upper()}: {sim:.4f} ({distinctiveness})\\n\"\n",
    "\n",
    "report += \"\\n\" + \"=\"*80\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140bab07",
   "metadata": {},
   "source": [
    "## 13. Detailed Concept Vector Magnitude Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the magnitude and direction of concept vectors\n",
    "fig, axes = plt.subplots(1, len(genres_of_interest), figsize=(16, 5))\n",
    "\n",
    "concept_magnitudes = {}\n",
    "\n",
    "for idx, genre in enumerate(genres_of_interest):\n",
    "    magnitudes = []\n",
    "    layer_indices = []\n",
    "    \n",
    "    for layer_name in selected_layers:\n",
    "        if layer_name in tcav_vectors[genre]:\n",
    "            vec = tcav_vectors[genre][layer_name].numpy()\n",
    "            magnitude = np.linalg.norm(vec)\n",
    "            magnitudes.append(magnitude)\n",
    "            layer_idx = int(layer_name.split('.')[-1])\n",
    "            layer_indices.append(layer_idx)\n",
    "    \n",
    "    concept_magnitudes[genre] = magnitudes\n",
    "    \n",
    "    # Plot magnitude across layers\n",
    "    axes[idx].plot(layer_indices, magnitudes, marker='o', linewidth=2, markersize=8, color=['#FF6B6B', '#4ECDC4', '#45B7D1'][idx])\n",
    "    axes[idx].fill_between(layer_indices, magnitudes, alpha=0.3, color=['#FF6B6B', '#4ECDC4', '#45B7D1'][idx])\n",
    "    axes[idx].set_title(f'{genre.upper()} Concept Vector Magnitude', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Layer Index')\n",
    "    axes[idx].set_ylabel('Vector Magnitude')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConcept Vector Magnitudes by Genre and Layer:\")\n",
    "print(\"=\" * 60)\n",
    "for genre in genres_of_interest:\n",
    "    print(f\"\\n{genre.upper()}:\")\n",
    "    mags = concept_magnitudes[genre]\n",
    "    print(f\"  Mean magnitude: {np.mean(mags):.4f}\")\n",
    "    print(f\"  Max magnitude:  {np.max(mags):.4f} (Layer {selected_layers[np.argmax(mags)].split('.')[-1]})\")\n",
    "    print(f\"  Min magnitude:  {np.min(mags):.4f} (Layer {selected_layers[np.argmin(mags)].split('.')[-1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf736f",
   "metadata": {},
   "source": [
    "## 14. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca5a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV and JSON\n",
    "output_dir = Path(\"../outputs/tcav_analysis\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export TCAV scores\n",
    "tcav_export_df = tcav_plot_df.copy()\n",
    "tcav_scores_path = output_dir / \"tcav_scores.csv\"\n",
    "tcav_export_df.to_csv(tcav_scores_path, index=False)\n",
    "print(f\"✓ TCAV scores exported to: {tcav_scores_path}\")\n",
    "\n",
    "# Export summary statistics\n",
    "summary_stats = {\n",
    "    'genre_average_scores': {genre: float(np.mean([tcav_scores[genre].get(layer, 0) for layer in selected_layers])) \n",
    "                             for genre in genres_of_interest},\n",
    "    'genre_max_scores': {genre: float(np.max([tcav_scores[genre].get(layer, 0) for layer in selected_layers])) \n",
    "                         for genre in genres_of_interest},\n",
    "    'critical_layers': {genre: {'layer': layer, 'score': float(score)} \n",
    "                       for genre, (layer, score) in layer_importance.items()},\n",
    "    'concept_similarity': {\n",
    "        f\"{g1}_vs_{g2}\": float(similarity_matrix[i, j])\n",
    "        for i, g1 in enumerate(genres_of_interest)\n",
    "        for j, g2 in enumerate(genres_of_interest)\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "summary_path = output_dir / \"tcav_summary.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "print(f\"✓ Summary statistics exported to: {summary_path}\")\n",
    "\n",
    "# Create a detailed report file\n",
    "report_path = output_dir / \"tcav_analysis_report.txt\"\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report)\n",
    "print(f\"✓ Detailed report exported to: {report_path}\")\n",
    "\n",
    "print(f\"\\nAll results saved to: {output_dir}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  - {tcav_scores_path.name}\")\n",
    "print(f\"  - {summary_path.name}\")\n",
    "print(f\"  - {report_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e763e5",
   "metadata": {},
   "source": [
    "## 15. Cleanup and Final Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b722777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up hooks to free memory\n",
    "for handle in handles:\n",
    "    handle.remove()\n",
    "\n",
    "print(\"✓ Hooks removed and memory cleaned up\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TCAV ANALYSIS COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "NEXT STEPS:\n",
    "-----------\n",
    "1. Review the generated visualizations and heatmaps\n",
    "2. Examine the exported CSV and JSON files in outputs/tcav_analysis/\n",
    "3. Consider the following questions:\n",
    "   - Which layers are most important for genre distinction?\n",
    "   - Are genre concepts well-separated or do they overlap?\n",
    "   - How do different genres activate different parts of the model?\n",
    "   \n",
    "INTERPRETATION GUIDE:\n",
    "--------------------\n",
    "- TCAV Score: Higher scores indicate stronger concept presence at that layer\n",
    "- Accuracy: Higher accuracy means the concept is more linearly separable\n",
    "- Similarity: Higher similarity between genres suggests overlapping representations\n",
    "- Vector Magnitude: Larger magnitudes indicate stronger concept expression\n",
    "\n",
    "For more details, see the full report in outputs/tcav_analysis/tcav_analysis_report.txt\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
