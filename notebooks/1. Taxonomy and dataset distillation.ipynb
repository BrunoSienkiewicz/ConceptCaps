{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "# Increase font sizes for readability\n",
    "sns.set_context('notebook', font_scale=1.4)\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (18, 8),\n",
    "    'font.size': 32,\n",
    "    'axes.titlesize': 28,\n",
    "    'axes.labelsize': 25,\n",
    "    'xtick.labelsize': 23,\n",
    "    'ytick.labelsize': 23,\n",
    "    'legend.fontsize': 21\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf51e4",
   "metadata": {},
   "source": [
    "## Load MusicCaps dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b387c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"google/MusicCaps\")\n",
    "df_train = ds['train'].to_pandas()\n",
    "df_train['aspect_list_transformed'] = df_train['aspect_list'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c79e4",
   "metadata": {},
   "source": [
    "### Analyse tag counts for concept extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4457b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts = {}\n",
    "for aspects in df_train['aspect_list_transformed']:\n",
    "    for tag in aspects:\n",
    "        if tag in tag_counts:\n",
    "            tag_counts[tag] += 1\n",
    "        else:\n",
    "            tag_counts[tag] = 1\n",
    "tag_counts_df = pd.DataFrame(list(tag_counts.items()), columns=['Tag', 'Count'])\n",
    "tag_counts_df = tag_counts_df.sort_values(by='Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tag_counts_df = tag_counts_df.head(20)\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.barplot(data=_tag_counts_df, x='Tag', y='Count', palette='viridis')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Tag Frequency in MusicCaps Dataset')\n",
    "plt.xlabel('Tags')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b528bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts_df.to_csv(\"../data/musiccaps_tag_frequencies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd09ae",
   "metadata": {},
   "source": [
    "## Prepare concept dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tags(song_tags, concept_tags):\n",
    "    res = []\n",
    "    for c_tag in concept_tags:\n",
    "        for s_tag in song_tags:\n",
    "            if c_tag == s_tag:\n",
    "                res.append(s_tag)\n",
    "    return list(set(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = json.load(open(\"../data/concepts_to_tags.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'low quality' from captions\n",
    "df_train['caption'] = df_train['caption'].str.replace('low quality', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c3e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept, tags in concepts.items():\n",
    "    df_train[concept + '_tags'] = df_train['aspect_list_transformed'].apply(\n",
    "        lambda x: extract_tags(x, tags)\n",
    "    )\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows with tags in at least 3 categories\n",
    "def count_nonempty_tags(row):\n",
    "    count = 0\n",
    "    for col in ['tempo_tags', 'genre_tags', 'mood_tags', 'instrument_tags']:\n",
    "        if row[col]:\n",
    "            count += 1\n",
    "    return count\n",
    "df_train = df_train[df_train.apply(count_nonempty_tags, axis=1) >= 3]\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[[\"caption\", \"aspect_list_transformed\", \"tempo_tags\", \"genre_tags\", \"mood_tags\", \"instrument_tags\"]]\n",
    "df_train[\"combined_tags\"] = df_train[\"tempo_tags\"] + df_train[\"genre_tags\"] + df_train[\"mood_tags\"] + df_train[\"instrument_tags\"]\n",
    "df_train[\"aspect_list\"] = df_train[\"combined_tags\"].apply(lambda x: ', '.join(x))\n",
    "df_train[\"tempo_tags\"] = df_train[\"tempo_tags\"].apply(lambda x: ', '.join(x))\n",
    "df_train[\"genre_tags\"] = df_train[\"genre_tags\"].apply(lambda x: ', '.join(x))\n",
    "df_train[\"mood_tags\"] = df_train[\"mood_tags\"].apply(lambda x: ', '.join(x))\n",
    "df_train[\"instrument_tags\"] = df_train[\"instrument_tags\"].apply(lambda x: ', '.join(x))\n",
    "df_train = df_train[[\"caption\", \"aspect_list\", \"tempo_tags\", \"genre_tags\", \"mood_tags\", \"instrument_tags\"]]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f622b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"../data/musiccaps_tags_to_description_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd5dec",
   "metadata": {},
   "source": [
    "## Analyse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/musiccaps_tags_to_description_dataset.csv\")\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_train = df_train.fillna('')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "tag_columns = [\"tempo_tags\", \"genre_tags\", \"mood_tags\", \"instrument_tags\", \"aspect_list\"]\n",
    "for col in tag_columns:\n",
    "    df_train[col + '_count'] = df_train[col].apply(lambda x: len(x.split(', ')))\n",
    "display(df_train[[col + '_count' for col in tag_columns]].describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tag len distribution\n",
    "tag_len_counts = df_train['aspect_list'].map(lambda x: len(x.split(', '))).value_counts().sort_index()\n",
    "plt.bar(tag_len_counts.index, tag_len_counts.values)\n",
    "plt.xlabel(\"Number of Tags\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.title(\"Distribution of Tag Counts in Training dataset\", fontweight='bold')\n",
    "plt.savefig(\"../docs/assets/tag_count_distribution_musiccaps.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of number of tags per category\n",
    "tag_columns = [\"tempo_tags\", \"genre_tags\", \"mood_tags\", \"instrument_tags\"]\n",
    "plt.figure(figsize=(20, 12))\n",
    "titles = ['Tempo Tags', 'Genre Tags', 'Mood Tags', 'Instrument Tags']\n",
    "for i, col in enumerate(tag_columns, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    tag_counts = df_train[col].apply(lambda x: len(x.split(', ')))\n",
    "    \n",
    "    # Create histogram with centered bin labels\n",
    "    n, bins, patches = plt.hist(tag_counts, bins=range(1, tag_counts.max() + 2), edgecolor='black')\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.xticks(bin_centers, [int(x) for x in bin_centers], rotation=0)\n",
    "    \n",
    "    plt.title(titles[i-1], fontweight='bold')\n",
    "    plt.xlabel('Number of Tags')\n",
    "    plt.ylabel('Frequency')\n",
    "plt.suptitle('Distribution of Number of Tags per Category\\nin Training Dataset', fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0.01, 1, 0.95])\n",
    "plt.savefig(\"../docs/assets/tag_count_distribution_per_category.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2419d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display distribution of caption lengths\n",
    "df_train['caption_length'] = df_train['caption'].apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_train['caption_length'], bins=30, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Caption Lengths\\nin Training dataset', fontweight='bold')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../docs/assets/caption_length_distribution_musiccaps.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a1c6a",
   "metadata": {},
   "source": [
    "## Save final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.1, random_state=42)\n",
    "df_valid, df_test = train_test_split(df_valid, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"../data/distilled-musiccaps\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_train.to_csv(output_dir / \"train.csv\", index=False)\n",
    "df_valid.to_csv(output_dir / \"validation.csv\", index=False)\n",
    "df_test.to_csv(output_dir / \"test.csv\", index=False)\n",
    "all_df = pd.concat([df_train, df_valid, df_test])\n",
    "all_df.to_csv(output_dir / \"all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train\": str(output_dir / \"train.csv\"),\n",
    "    \"validation\": str(output_dir / \"validation.csv\"),\n",
    "    \"test\": str(output_dir / \"test.csv\")\n",
    "}\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "dataset.push_to_hub(\"bsienkiewicz/distilled-musiccaps\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-gen-interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
